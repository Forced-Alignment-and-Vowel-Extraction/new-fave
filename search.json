[
  {
    "objectID": "command/index.html",
    "href": "command/index.html",
    "title": "new-fave Command Builder",
    "section": "",
    "text": "This page is meant to assist you in constructing a new-fave command. It does not run new-fave itself.\n\n\n\n{\n  let btn = Inputs.button(\n    \"Copy to Clipboard\",\n    {\n      value: null,\n      reduce: () =&gt;\n        navigator.clipboard.writeText(fullText)\n    }\n  )\n  return html`${btn}`\n}\n\n\n\n\n\n\n\nfullText = `fave-extract ${subcommand} ${data_path}${speaker_flag}${aligner_flag}${recodeCode}${add_code}${parser_code}${measurement_flag}${ft_flag}${exclude_flag}${no_optim_flag}${f1_flag}${f2_flag}${destination_flag}${separate_flag}${which_flags}${reference_flag}`\n\nmd`\n\\`\\`\\`bash\n${fullText}\n\\`\\`\\`\n`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmd`### Subcommand`\n\n\n\n\n\n\n\nviewof subcommand = Inputs.radio(\n  [\"audio-textgrid\", \"corpus\", \"subcorpora\"], \n  {\n    label: md`[subcommand](../usage/getting_started.html#usage)`,\n    value: \"audio-textgrid\"\n  }\n)\n\naudio_label = {\n  if (subcommand == \"audio-textgrid\"){\n    return md`[audio file](../usage/getting_started.html#audio-textgrid)`\n  } else if (subcommand == \"corpus\"){\n    return md`[corpus path](../usage/getting_started.html#corpus)`\n  } else if (subcommand == \"subcorpora\"){\n    return md`[subcorpus glob](../usage/getting_started.html#subcorpora)`\n  }\n}\n\naudio_default = {\n  if (subcommand == \"audio-textgrid\"){\n    return \"speaker.wav\"\n  } else if (subcommand == \"corpus\"){\n    return \"corpus/\"\n  } else if (subcommand == \"subcorpora\"){\n    return \"corpus/*\"\n  }\n}\n\ntextgrid_path = {\n  if(subcommand == \"audio-textgrid\"){\n    return Inputs.text(\n      {\n        label: \"textgrid file\",\n        value: \"speaker.TextGrid\"\n      }\n    )\n  }\n}\n\ntextgrid_use = {\n  if (subcommand == \"audio-textgrid\"){\n    return Generators.input(textgrid_path)\n  }\n}\n\nviewof audio_path = Inputs.text(\n  {\n    label: audio_label,\n    value: audio_default\n  }\n)\n\ntextgrid_path != undefined ? \n  html`${textgrid_path}` :\n  md``\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndata_path = {\n  if (subcommand == \"audio-textgrid\"){\n    return `${audio_path} ${textgrid_use}`\n  } else {\n    return `${audio_path}`\n  }\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProcessing Info\n\n\n\n\n\n\nmd`### Speaker(s) to analyze`\n\n\n\n\n\n\n\nviewof speaker = Inputs.radio(\n  [\"single speaker\", \"all speakers\", \"demographic file\"],\n  {\n    label: \"speaker\",\n    value: \"single speaker\"\n  }\n)\n\nspeaker_input = {\n  if (speaker == \"single speaker\"){\n    return Inputs.range(\n      [1, 10], \n      {\n        label: \"speaker number\",\n        step: 1,\n        value: 1\n      }\n    )\n  } else if(speaker == \"demographic file\"){\n    return Inputs.text(\n      {\n        label: md`[demographic file](../usage/customizing/demographics.html)`,\n        required: true\n      }\n    )\n  }\n}\n\nspeaker_input != undefined ?\n  html`${speaker_input}` :\n  md``\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nspeaker_use = {\n  if(speaker == \"all speakers\"){\n    return \"all\"\n  }else{\n    return Generators.input(speaker_input)\n  }\n}\n\nspeaker_flag = {\n  if (speaker == \"single speaker\"){\n    if (speaker_use &gt; 1){\n      return ` \\\\ \n  --speakers ${speaker_use}`\n    }else{\n      return \"\"\n    }\n  } else {\n    return ` \\\\\n  --speakers ${speaker_use}`\n  }\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmd`### Aligner`\n\n\n\n\n\n\n\nviewof aligner = Inputs.radio(\n  [\"mfa\", \"fave-align\"],\n  {\n    label: \"aligner used\",\n    value: \"mfa\"\n  }\n)\n\naligner_flag = {\n  if (aligner == \"fave-align\"){\n    return ` \\\\\n  --fave-aligned`\n  }else{\n    return \"\"\n  }\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmd`### [Recode rules](../usage/configs/recode-rules.html)`\n\n\n\n\n\n\n\nviewof recode = Inputs.radio(\n  [\"cmu2labov\", \"cmu2phila\", \"norecode\", \"custom\"], \n  {\n    label: \"recode rules\",\n    value: \"cmu2labov\"\n  }\n)\n\nrecodepath = {\n  if(recode == \"custom\"){\n    return  Inputs.text(\n      {\n        label: \"recode rules file:\", \n        required: true\n      }\n    )\n  }\n}\n\nrecodepath != undefined ? \n  html`${recodepath}` :\n  md``\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nviewof add_rules = Inputs.toggle(\n  {\n    label: \"additional rules\", \n    value: false\n  }\n)\n\nadd_path = {\n  if(add_rules){\n    return Inputs.text(\n      {\n        label: \"additional rules file\",\n        required: true\n      }\n    )\n  }\n}\n\nadd_path != undefined? \n  html`${add_path}` :\n  md``\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nrecodeuse = {\n  if (recode != \"cmu2labov\"){\n    if(recode == \"custom\"){\n      return Generators.input(recodepath)\n    } else {\n      return recode\n    }\n  } \n}\n\nadd_use = {\n  if(add_rules){\n    return Generators.input(add_path)\n  }\n}\n\nrecodeCode = {\n  if (recode != \"cmu2labov\"){\n    return ` \\\\\n  --recode-rules ${recodeuse}`\n  } else {\n    return \"\"\n  }\n}\n\nadd_code = {\n  if(add_rules){\n    return ` \\\\ \n  --add_rules ${add_use}`\n  }else{\n    return \"\"\n  }\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmd`### [Measurement point heuristic](../usage/configs/point-heuristic.html)`\n\n\n\n\n\n\n\nviewof measurement_point = Inputs.text(\n  {\n    label: \"measurement point heuristic\",\n    value: \"fave\"\n  }\n)\n\nmeasurement_flag = {\n  if(measurement_point != \"fave\"){\n    return ` \\\\\n  --point-heuristic ${measurement_point}`\n  }else{\n    return \"\"\n  }\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmd`### [FastTrack Config](../usage/configs/ft-config.html)`\n\n\n\n\n\n\n\nviewof ft_config = Inputs.text(\n  {\n    label: \"FastTrack configuration\",\n    value: \"default\"\n  }\n)\n\nft_flag = {\n  if(ft_config != \"default\"){\n    return ` \\\\\n  --ft-config ${ft_config}`\n  }else{\n    return \"\"\n  }\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmd`### [Misc Processing](../usage/customizing/processing.html)`\n\n\n\n\n\n\n\nviewof exclude_overlaps = Inputs.toggle(\n  {\n    label: \"exclude overlaps\",\n    value: false\n  }\n)\n\nviewof no_optimize = Inputs.toggle(\n  {\n    label: \"no optimization\",\n    value: false\n  }\n)\n\nviewof f1_cutoff = Inputs.range(\n  [500, 2500],\n  {\n    label: \"F1 cutoff\",\n    step: 1\n  }\n)\n\nviewof f2_cutoff = Inputs.range(\n  [2500, 4500],\n  {\n    label: \"F2 cutoff\",\n    step: 1\n  }\n)\n\nexclude_flag = {\n  if(exclude_overlaps){\n    return ` \\\\\n  --exclude-overlaps`\n  }else{\n    return \"\"\n  }\n}\n\nno_optim_flag = {\n  if(no_optimize){\n    return ` \\\\\n  --no-optimize`\n  }else{\n    return \"\"\n  }\n}\n\nf1_flag = {\n  if(f1_cutoff != 1500){\n    return ` \\\\\n  --f1-cutoff ${f1_cutoff}`\n  }else{\n    return \"\"\n  }\n}\n\nf2_flag = {\n  if(f2_cutoff != 3500){\n    return ` \\\\\n  --f2-cutoff ${f2_cutoff}`\n  }else{\n    return \"\"\n  }\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdvanced Processing options\n\nviewof labelset_parser = Inputs.toggle(\n  {\n    label: \"custom labelset parser\", \n    value: false\n  }\n)\n\nparser_path = {\n  if(labelset_parser){\n    return Inputs.text(\n      {\n        label: md`labelset parser file`,\n        required: true\n      }\n    )\n  }\n}\n\nparser_path != undefined? \n  html`${parser_path}` :\n  md``\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nparser_use = {\n  if(labelset_parser){\n    return Generators.input(parser_path)\n  }\n}\n\nparser_code = {\n  if(labelset_parser){\n    return ` \\\\ \n  --labelset_parser ${parser_use}`\n  }else{\n    return \"\"\n  }\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOutput Options\n\n\n\n\n\n\nmd`### [Output Options](../usage/customizing/output.html)`\n\n\n\n\n\n\n\nviewof destination = Inputs.text(\n  {\n    label: \"results directory\",\n    value: \"fave_results\"\n  }\n)\n\nviewof separate = Inputs.toggle(\n  {\n    label: \"one speaker per file\",\n    value: false\n  }\n)\n\nviewof formats = Inputs.select(\n  [\"tracks\", \"points\", \"param\", \"log_param\", \"textgrid\"],\n  {\n    label: \"output formats\",\n    value: [\"tracks\", \"points\", \"param\", \"log_param\", \"textgrid\"],\n    multiple: true\n  }\n)\n\ndestination_flag = {\n  if(destination != \"fave_results\"){\n    return ` \\\\\n  --destination ${destination}`\n  }else{\n    return \"\"\n  }\n}\n\nseparate_flag = {\n  if(separate){\n    return ` \\\\\n  --separate`\n  }else{\n    return \"\"\n  }\n}\n\nwhich_flags = {\n  if(formats.length &lt; 5){\n    return formats.reduce(\n      (accumulator, current) =&gt; `${accumulator} \\\\\n  --which ${current}`,\n    \"\"\n    )\n  }else{\n    return\"\"\n  }\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReference Value Options\n\n\n\n\n\n\nmd`### [Reference Values](../usage/customizing/reference.html)`\n\n\n\n\n\n\n\nviewof reference_type = Inputs.radio(\n  [\"logparam\", \"param\", \"points\", \"none\"],\n  {\n    label: \"reference corpus type\",\n    value: \"none\"\n  }\n)\n\n\nreference_path = {\n  if(reference_type != \"none\"){\n    return Inputs.text(\n      {\n        value: \"corpus\",\n        label: \"reference corpus path\",\n        required: true\n      }\n    )\n  }\n}\n\nreference_path != undefined ?\n  html`${reference_path}` :\n  md``\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nreference_use = {\n  if(reference_type != \"none\"){\n    return Generators.input(reference_path)\n  }\n}\n\nreference_flag = {\n  if(reference_type != \"none\"){\n    return ` \\\\\n  --${reference_type}-reference ${reference_use}`\n  }else{\n    return \"\"\n  }\n}"
  },
  {
    "objectID": "usage/outputs/index.html",
    "href": "usage/outputs/index.html",
    "title": "fave-extract Outputs",
    "section": "",
    "text": "The subcommands of fave-extract generate multiple output files by default (this can be customized). Each one will be named after the original file with a suffix. Below, each type of output file is described, followed by descriptions of the data columns in the csv files (in alphabetical order).",
    "crumbs": [
      "Home",
      "Usage",
      "`fave-extract` Outputs"
    ]
  },
  {
    "objectID": "usage/outputs/index.html#file-types",
    "href": "usage/outputs/index.html#file-types",
    "title": "fave-extract Outputs",
    "section": "File Types",
    "text": "File Types\n\n*_points.csv\nPoints files contain 1 row per vowel analyzed, with a single point measurement taken according to the measurement point heuristic used.\n\n\n*_tracks.csv\nTracks files contain 1 row per measurement point per vowel analyzed. By default, there will be one measurement point every 2ms, so a 100ms vowel will have 50 rows in the data. `*_tracks.csv* files can get very large!\nFor analyzing the tracks data, the combination of the file_name column and the id will uniquely identify each individual token.\n\n\n*_param.csv and *_logparam.csv\nThese files contain the Discrete Cosine Transform coefficients for each analyzed vowel. *_param.csv contains the coefficients when the DCT is applied to the formants in Hz, and *_logparam.csv contains the coefficients when the DCT is applied to the log-transformed formants.\nThe DCT coefficients can be directly normalized (R package). This can be useful for\n\nDecreasing the memory size of your data.\nAveraging over formant tracks.\nDoing statistics.\n\n\n\n*_recoded.TextGrid\nThe *_recoded.TextGrid will be a copy of the original textgrid passed to new-fave to which the recode rules have been applied.",
    "crumbs": [
      "Home",
      "Usage",
      "`fave-extract` Outputs"
    ]
  },
  {
    "objectID": "usage/outputs/index.html#data-columns",
    "href": "usage/outputs/index.html#data-columns",
    "title": "fave-extract Outputs",
    "section": "Data Columns",
    "text": "Data Columns\nThe data columns are described in this searchable table, and in text below.\n\n\n\n\n\n\n\n\n\n\nAlphabetic List\n\nabs_fol_seg\nStands for ‘absolute following segment’. The segment following the measured vowel, regardless of word boundary.\n\n\nabs_pre_seg\nStands for ‘absolute preceding segment’. The segment preceding the measured vowel, regardless of word boundary.\n\n\nB1, B2, B3\nThe bandwidths of F1, F2, and F3.\n\n\ncontext\nThe broad location of the measured vowel within the word.\n\n\ndur\nThe duration of the measured vowel.\n\n\nF1, F3, F3\nIn points and tracks files, the estimated formant values. In param and logparam files, DCT coefficients for each formant.\n\n\nF1_s, F2_s, F3_s\nThese only appear in tracks files. The DCT smoothed formant tracks\n\n\nfile_name\nThe file stem of the analyzed file\n\n\nfol_seg\nThe segment following the measured vowel. If the vowel is at the end of the word, this is ‘#’\n\n\nfol_word\nThe word following the word that the measured vowel appears in.\n\n\ngroup\nThe name of the word+phone tier group in the original textgrid. If tiers were just named ‘word’ and ‘phone’, this will be ‘group_0’. Otherwise, this will probably be the speaker’s name.\n\n\nid\nA unique id for the measured vowel that is shared across all file outputs. The numbers correspond to [the index of the tier group]-[the index of the word tier]-[the index of the word within the tier]-[the index of the vowel within the word].\n\n\nlabel\nThe label of the measured vowel.\n\n\nmax_formant\nThe maximum formant setting used for this vowel\n\n\noptimized\nThe number of optimization iterations that ran.\n\n\nparam\nThis only appears in param and logparam files. It identifies which DCT coefficient this row corresponds to.\n\n\npoint_heuristic\nThis only appears in points files. Identifies the measurement point heuristic used.\n\n\npre_seg\nThe segment preceding the measured vowel. If the vowel is at the beginning edge of the word, this is ‘#’.\n\n\npre_word\nThe word preceding the word that the measured vowel appears in.\n\n\nprop_time\nTime measured proportionally to the duration of the vowel. The very beginning of the vowel is time 0, and the very end is time 1.\n\n\nrel_time\nTime relative to the start of the vowel, in seconds. The very beginning of the vowel is time 0.\n\n\nsmooth_error\nAmeasure of of the mismatch between the formant track smooths and the raw formant track estimates. A larger value corresponds to a larger mismatch.\n\n\nspeaker_num\nThe speaker index in the textgrid (beginning at 1)\n\n\nstress\nIf present, the stress of the measured vowel\n\n\ntime\nThe time within the full recording, in seconds. The beginning of the recording is 0\n\n\nword\nThe word that the measured vowel appeared in.",
    "crumbs": [
      "Home",
      "Usage",
      "`fave-extract` Outputs"
    ]
  },
  {
    "objectID": "usage/customizing/reference.html",
    "href": "usage/customizing/reference.html",
    "title": "Reference Values",
    "section": "",
    "text": "If you already have a collection of new-fave or legacy-fave results, and would like to use these formant values as a reference to cut down on formant tracking errors, you can pass them to a fave-extract subcommand. The option to use will depend on the kind of reference values you are using.\n\nPoint Values Reference\nIf you have a collection of vowel formant point values, either extracted by new-fave or legacy-fave, you can point the fave-extract subcommands at this corpus with the --points-reference option.\n# command-line\nfave-extract audio-textgrid \\\n    speaker1.wav speaker1.TextGrid \\\n    --points-reference fave_results\n\n\nParam Reference\nIf you have a collection of vowel formant DCT smoothing parameters, you can point the fave-extract subcommands at this corpus with the --param-reference option.\n# command-line\nfave-extract audio-textgrid \\\n    speaker1.wav speaker1.TextGrid \\\n    --param-reference fave_results\n\n\nLog-Param Reference\nIf you have a collection of vowel log(formant) DCT smoothing parameters, you can point the fave-extract subcommands at this corpus with the --logparam-reference option.\n# command-line\nfave-extract audio-textgrid \\\n    speaker1.wav speaker1.TextGrid \\\n    --logparam-reference fave_results",
    "crumbs": [
      "Home",
      "Usage",
      "Customizing",
      "Reference Values"
    ]
  },
  {
    "objectID": "usage/customizing/output.html",
    "href": "usage/customizing/output.html",
    "title": "Output Options",
    "section": "",
    "text": "By default, the fave-extract subcommands will write all possible data outputs to a directory called fave_results/. You can control how this works with a few options.",
    "crumbs": [
      "Home",
      "Usage",
      "Customizing",
      "Output Options"
    ]
  },
  {
    "objectID": "usage/customizing/output.html#tracks",
    "href": "usage/customizing/output.html#tracks",
    "title": "Output Options",
    "section": "tracks",
    "text": "tracks\nTo only save vowel formant track data as a .csv, pass tracks to the --which option.\nfave-extract corpus my_corpus \\\n    --which tracks",
    "crumbs": [
      "Home",
      "Usage",
      "Customizing",
      "Output Options"
    ]
  },
  {
    "objectID": "usage/customizing/output.html#points",
    "href": "usage/customizing/output.html#points",
    "title": "Output Options",
    "section": "points",
    "text": "points\nTo only save vowel formant point data as a .csv, pass points to the --which option.\nfave-extract corpus my_corpus \\\n    --which points",
    "crumbs": [
      "Home",
      "Usage",
      "Customizing",
      "Output Options"
    ]
  },
  {
    "objectID": "usage/customizing/output.html#param",
    "href": "usage/customizing/output.html#param",
    "title": "Output Options",
    "section": "param",
    "text": "param\nTo only save DCT smooth parameters, pass param to the --which option.\nfave-extract corpus my_corpus \\\n    --which param",
    "crumbs": [
      "Home",
      "Usage",
      "Customizing",
      "Output Options"
    ]
  },
  {
    "objectID": "usage/customizing/output.html#log-param",
    "href": "usage/customizing/output.html#log-param",
    "title": "Output Options",
    "section": "log param",
    "text": "log param\nTo only save DCT smooth parameters of log(formants), pass log_param to the --which option.\nfave-extract corpus my_corpus \\\n    --which log_param",
    "crumbs": [
      "Home",
      "Usage",
      "Customizing",
      "Output Options"
    ]
  },
  {
    "objectID": "usage/customizing/output.html#textgrid",
    "href": "usage/customizing/output.html#textgrid",
    "title": "Output Options",
    "section": "textgrid",
    "text": "textgrid\nTo only save the recoded textgrid, pass textgrid to the --which option.\nfave-extract corpus my_corpus \\\n    --which textgrid",
    "crumbs": [
      "Home",
      "Usage",
      "Customizing",
      "Output Options"
    ]
  },
  {
    "objectID": "usage/customizing/output.html#multiple",
    "href": "usage/customizing/output.html#multiple",
    "title": "Output Options",
    "section": "Multiple",
    "text": "Multiple\nIf there are multiple (but not all) output formats you would like to save, you can pass the --which option multiple times.\nfave-extract corpus my_corpus \\\n    --which tracks \\\n    --which points",
    "crumbs": [
      "Home",
      "Usage",
      "Customizing",
      "Output Options"
    ]
  },
  {
    "objectID": "usage/python_usage.html",
    "href": "usage/python_usage.html",
    "title": "Python Usage",
    "section": "",
    "text": "To use new-fave, you will need to have python installed on your computer. Currently, new-fave supports python versions 3.10, 3.11, 3.12, or 3.13. If you are not sure whether python is installed, or what version is installed, here is a good tutorial for figuring that out.\nOnce you have python successfully installed, you can install new-fave at the command-line like so.\n# command-line\npip install new-fave",
    "crumbs": [
      "Home",
      "Usage",
      "Python Usage"
    ]
  },
  {
    "objectID": "usage/python_usage.html#audio-textgrid",
    "href": "usage/python_usage.html#audio-textgrid",
    "title": "Python Usage",
    "section": "Audio + TextGrid",
    "text": "Audio + TextGrid\nSee fave_audio_textgrid and write_data. And if desired, SpeakerCollection.\nfrom new_fave import fave_audio_textgrid, write_data\n\nspeakers = fave_audio_textgrid(\n    audio_path = \"speaker1.wav\",\n    textgrid_path = \"speaker2.TextGrid\",\n    ## all optional args below\n    speakers = \"all\",\n    recode_rules = \"cmu2labov\",\n    labelset_parser = \"cmu_parser\",\n    point_heuristic = \"fave\",\n    ft_config = \"default\"\n)\n\nwrite_data(\n    speakers, \n    destination = \"output_dir\"\n)",
    "crumbs": [
      "Home",
      "Usage",
      "Python Usage"
    ]
  },
  {
    "objectID": "usage/python_usage.html#corpus",
    "href": "usage/python_usage.html#corpus",
    "title": "Python Usage",
    "section": "Corpus",
    "text": "Corpus\nSee fave_corpus and write_data. And if desired, SpeakerCollection.\nfrom new_fave import fave_corpus, write_data\n\nspeakers = fave_corpus(\n    corpus_path = \"corpus/\",\n    ## all optional args below\n    speakers = \"all\",\n    recode_rules = \"cmu2labov\",\n    labelset_parser = \"cmu_parser\",\n    point_heuristic = \"fave\",\n    ft_config = \"default\"\n)\n\nwrite_data(\n    speakers, \n    destination = \"output_dir\"\n)",
    "crumbs": [
      "Home",
      "Usage",
      "Python Usage"
    ]
  },
  {
    "objectID": "usage/python_usage.html#subcorpora",
    "href": "usage/python_usage.html#subcorpora",
    "title": "Python Usage",
    "section": "Subcorpora",
    "text": "Subcorpora\nSee fave_subcorpora and write_data. And if desired, SpeakerCollection.\nfrom new_fave import fave_subcorpora, write_data\n\nspeakers = fave_subcorpora(\n    subcorpora_glob = \"project/speakers/*/\",\n    ## all optional args below\n    speakers = \"all\",\n    recode_rules = \"cmu2labov\",\n    labelset_parser = \"cmu_parser\",\n    point_heuristic = \"fave\",\n    ft_config = \"default\"\n)\n\nwrite_data(\n    speakers, \n    destination = \"output_dir\"\n)",
    "crumbs": [
      "Home",
      "Usage",
      "Python Usage"
    ]
  },
  {
    "objectID": "usage/configs/index.html",
    "href": "usage/configs/index.html",
    "title": "Config Files",
    "section": "",
    "text": "new-fave Defaults\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFastTrack Config\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMeasurement Point Customization\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRecode Rules and Labelset Parser\n\n\n\n\n\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Home",
      "Usage",
      "Configuration"
    ]
  },
  {
    "objectID": "usage/configs/defaults.html",
    "href": "usage/configs/defaults.html",
    "title": "new-fave Defaults",
    "section": "",
    "text": "recode rules\n\n\n\n\n\ncmu2labov\n\n\ncmu2labov.yml\n\n- rule: sp-ns-to-blank\n  conditions:\n    - attribute: label\n      relation: in\n      set:\n        - sp\n        - \"{NS}\"\n  return: \"\"\n\n- rule: schwa\n  conditions:\n    - attribute: label\n      relation: ==\n      set: AH0\n  return: \"@\"\n- rule: eyf\n  conditions: \n    - attribute: label\n      relation: contains\n      set: EY\n    - attribute: fol.label\n      relation: ==\n      set: \"#\"\n  return: eyF\n- rule: iyF\n  conditions: \n    - attribute: label\n      relation: contains\n      set: IY\n    - attribute: fol.label\n      relation: ==\n      set: \"#\"\n  return: iyF\n- rule: owF\n  conditions: \n    - attribute: label\n      relation: contains\n      set: OW\n    - attribute: fol.label\n      relation: ==\n      set: \"#\"\n  return: owF\n- rule: ay0\n  conditions:\n    - attribute: label\n      relation: contains\n      set: AY\n    - attribute: fol.label\n      relation: in\n      set: \n        - CH\n        - F\n        - HH\n        - K\n        - P\n        - S\n        - SH\n        - T\n        - TH\n  return: ay0\n- rule: ah\n  conditions:\n    - attribute: label\n      relation: contains\n      set: AA\n    - attribute: inword.label\n      relation: in\n      set: \n        - FATHER\n        - FATHER\n        - FATHER'S\n        - MA\n        - MA'S\n        - PA\n        - PA'S\n        - SPA\n        - SPAS\n        - SPA'S\n        - CHICAGO\n        - CHICAGO'S\n        - PASTA\n        - BRA\n        - BRAS\n        - BRA'S\n        - UTAH\n        - TACO\n        - TACOS\n        - TACO'S\n        - GRANDFATHER\n        - GRANDFATHERS\n        - GRANDFATHER'S\n        - CALM\n        - CALMER\n        - CALMEST\n        - CALMING\n        - CALMED\n        - CALMS\n        - PALM\n        - PALMS\n        - BALM\n        - BALMS\n        - ALMOND\n        - ALMONDS\n        - LAGER\n        - SALAMI\n        - NIRVANA\n        - KARATE\n        - AH\n  return: ah\n- rule: Tuw\n  conditions:\n    - attribute: label\n      relation: contains\n      set: UW\n    - attribute: prev.label\n      relation: in\n      set:\n        - AXR\n        - D\n        - DX\n        - EL\n        - EN\n        - L\n        - N\n        - R\n        - S\n        - T \n        - Z\n  return: Tuw\n- rule: iyr\n  conditions:\n    - attribute: label\n      relation: in\n      set: \n        - IH0\n        - IH1\n        - IH2\n        - IY0\n        - IY1\n        - IY2\n    - attribute: fol.label\n      relation: in\n      set: \n        - AXR\n        - R\n  return: iyr\n- rule: eyr\n  conditions: \n    - attribute: label\n      relation: contains\n      set: EY\n    - attribute: fol.label\n      relation: in\n      set:\n        - AXR\n        - R\n  return: eyr\n- rule: ahr\n  conditions:\n    - attribute: label\n      relation: contains\n      set: AA\n    - attribute: fol.label\n      relation: in\n      set: \n        - AXR\n        - R\n  return: ahr\n- rule: owr\n  conditions:\n    - attribute: label\n      relation: in\n      set: \n        - AO0\n        - AO1\n        - AO2\n        - OW0\n        - OW1\n        - OW2\n    - attribute: fol.label\n      relation: in\n      set:\n        - AXR\n        - R\n  return: owr\n- rule: uwr\n  conditions: \n    - attribute: label\n      relation: in\n      set: \n        - UH0\n        - UH1\n        - UH2\n        - UW0\n        - UW1\n        - UW2\n    - attribute: fol.label\n      relation: in\n      set:\n        - AXR\n        - R\n  return: uwr\n- rule: o\n  conditions:\n    - attribute: label\n      relation: contains\n      set: AA\n  return: o\n- rule: ae\n  conditions: \n    - attribute: label\n      relation: contains\n      set: AE\n  return: ae\n- rule: wedge\n  conditions:\n    - attribute: label\n      relation: in\n      set:\n        - AH1\n        - AH2\n  return: ʌ\n- rule: oh\n  conditions:\n    - attribute: label\n      relation: contains\n      set: AO\n  return: oh\n- rule: aw\n  conditions:\n    - attribute: label\n      relation: contains\n      set: AW\n  return: aw\n- rule: ay\n  conditions:\n    - attribute: label\n      relation: contains\n      set: AY\n  return: ay\n- rule: e\n  conditions:\n    - attribute: label\n      relation: contains\n      set: \"EH\"\n  return: e\n- rule: \"*hr\"\n  conditions:\n    - attribute: label\n      relation: contains\n      set: ER\n  return: \"*hr\"\n- rule: ey\n  conditions:\n    - attribute: label\n      relation: contains\n      set: EY\n  return: ey\n- rule: i\n  conditions:\n    - attribute: label\n      relation: contains\n      set: IH\n  return: i\n- rule: iy\n  conditions:\n    - attribute: label\n      relation: contains\n      set: IY\n  return: iy\n- rule: ow\n  conditions:\n    - attribute: label\n      relation: contains\n      set: OW\n  return: ow\n- rule: oy\n  conditions: \n    - attribute: label\n      relation: contains\n      set: OY\n  return: oy\n- rule: u\n  conditions: \n    - attribute: label\n      relation: contains\n      set: UH\n  return: u\n- rule: uw\n  conditions:\n    - attribute: label\n      relation: contains\n      set: UW\n  return: uw\n\n\n\n\n\n\n\n\n\n\nlabelset parser\n\n\n\n\n\ncmu2labov\n\n\ncmu_parser.yml\n\nparser: \"CMU\"\n\nproperties:\n  - name: \"stress\"\n    updates: \"stress\"\n    default: \"\"\n    rules:\n\n      - rule: \"1\"\n        conditions:\n          - attribute: label\n            relation: contains\n            set: \"1\"\n        return: \"1\"\n\n      - rule: \"2\"\n        conditions:\n          - attribute: label\n            relation: contains\n            set: \"2\"\n        return: \"2\"\n\n      - rule: \"0\"\n        conditions:\n          - attribute: label\n            relation: contains\n            set: \"0\"\n        return: \"0\"\n  \n  - name: \"coloring\"\n    updates: \"LR\"\n    default: \"\"\n    rules:\n      - rule: \"R\"\n        conditions: \n          - attribute: fol.label\n            relation: in\n            set: \n              - R\n              - AXR\n        return: \"R\"\n      - rule: \"L\"\n        conditions:\n          - attribute: fol.label\n            relation: \"==\"\n            set: L\n        return: L\n\n\n\n\n\n\n\n\n\n\nmeasurement point\n\n\n\n\n\ncmu2labov\n\n\nfave_measurement.yml\n\nheuristic: fave\ndefault:\n  prop_time: \"1/3\"\nspecifics:\n  - label: ay\n    prop_time: f1.max.prop_time\n  - label: ay0\n    prop_time: f1.max.prop_time\n  - label: ey\n    prop_time: f1.max.prop_time\n  - label: eyF\n    prop_time: f1.max.prop_time\n  - label: aw\n    prop_time: f1.max.prop_time / 2\n  - label: ow\n    prop_time: f1.max.prop_time / 2\n  - label: owF\n    prop_time: f1.max.prop_time / 2\n  - label: Tuw\n    prop_time: \"0.0\"",
    "crumbs": [
      "Home",
      "Usage",
      "Configuration",
      "new-fave Defaults"
    ]
  },
  {
    "objectID": "usage/index.html",
    "href": "usage/index.html",
    "title": "Usage",
    "section": "",
    "text": "Getting Started\n\n\nCommand-Line Usage\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPython Usage\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow it works\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnew-fave Defaults\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdding Speaker Demographics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConfig Files\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCustomizing\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFastTrack Config\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMeasurement Point Customization\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOutput Options\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProcessing Options\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRecode Rules and Labelset Parser\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReference Values\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfave-extract Outputs\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\naudio-textgrid\n\n\n\n\n\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Home",
      "Usage"
    ]
  },
  {
    "objectID": "usage/how_it_works.html",
    "href": "usage/how_it_works.html",
    "title": "How it works",
    "section": "",
    "text": "A fave-extract on a single audio file/textgrid pair takes place in 4 steps.",
    "crumbs": [
      "Home",
      "Usage",
      "How it works"
    ]
  },
  {
    "objectID": "usage/how_it_works.html#why-bother-with-label-recoding",
    "href": "usage/how_it_works.html#why-bother-with-label-recoding",
    "title": "How it works",
    "section": "Why bother with label recoding?",
    "text": "Why bother with label recoding?\nIn the next stage, optimization, distributional statistics are estimated and iteratively updated for each vowel class. Vowel classes are determined by their label, so if there are two distinct vowel classes that you are interested in, but they both have the same label in the original textgrid, you will have to recode them to be separate for optimization.",
    "crumbs": [
      "Home",
      "Usage",
      "How it works"
    ]
  },
  {
    "objectID": "dev/variable_names.html",
    "href": "dev/variable_names.html",
    "title": "Variable Naming Conventions",
    "section": "",
    "text": "cand: candidate tracks.\n\nReturns\n\nlist of fasttrackpy.OneTracks\na numpy.array of concatenated results from fasttrackpy.OneTracks\n\n\nwinner: The winner track\n\nReturns\n\nA single fasttrackpy.OneTrack\na numpy.array of concatenated results from winner fasttrackpy.OneTracks\n\n\n\n\n\n\n\nparam: The DCT parameters\nmaxformant: The maximum formant\nerror: The smoothing error term\nbparam: The formant bandwidths parameters\n\n\n\n\n\nmean: A mean\ncov: A covariance matrix\nicov: An inverse covariance matrix\n\n\n\n\n\nmahal: Mahalanobis distance\nlogprob: The log probability\n\n\n\n\n\nvm: Vowel Measurement\nvclass: Vowel Class\nspeaker: Speaker\ncorpus: Corpus\n\n\n\n\n\nglobal: Global\nbyvclass: By VowelClass"
  },
  {
    "objectID": "dev/variable_names.html#property-naming-descriptors",
    "href": "dev/variable_names.html#property-naming-descriptors",
    "title": "Variable Naming Conventions",
    "section": "",
    "text": "cand: candidate tracks.\n\nReturns\n\nlist of fasttrackpy.OneTracks\na numpy.array of concatenated results from fasttrackpy.OneTracks\n\n\nwinner: The winner track\n\nReturns\n\nA single fasttrackpy.OneTrack\na numpy.array of concatenated results from winner fasttrackpy.OneTracks\n\n\n\n\n\n\n\nparam: The DCT parameters\nmaxformant: The maximum formant\nerror: The smoothing error term\nbparam: The formant bandwidths parameters\n\n\n\n\n\nmean: A mean\ncov: A covariance matrix\nicov: An inverse covariance matrix\n\n\n\n\n\nmahal: Mahalanobis distance\nlogprob: The log probability\n\n\n\n\n\nvm: Vowel Measurement\nvclass: Vowel Class\nspeaker: Speaker\ncorpus: Corpus\n\n\n\n\n\nglobal: Global\nbyvclass: By VowelClass"
  },
  {
    "objectID": "dev/variable_names.html#property-naming-structure",
    "href": "dev/variable_names.html#property-naming-structure",
    "title": "Variable Naming Conventions",
    "section": "Property Naming Structure",
    "text": "Property Naming Structure\n\nsource_value_derived_scope_subdivision\nsource_value_summary\nsource_value"
  },
  {
    "objectID": "reference/pickle_speakers.html",
    "href": "reference/pickle_speakers.html",
    "title": "pickle_speakers",
    "section": "",
    "text": "pickle_speakers(speakers, path)\nThis will serialize a SpeakerCollection to a pickle file, that can be re-read in a new python session.\nNote: new-fave uses the cloudpickle library, rather than the standard pickle library, which comes with the following limitations, according to the cloudpickle documentation:\n\nCloudpickle can only be used to send objects between the exact same version of Python.\nUsing cloudpickle for long-term object storage is not supported and strongly discouraged.\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nspeakers\nSpeakerCollection\nA SpeakerCollection to serialize\nrequired\n\n\npath\nstr | Path\nThe destination file to save the pickle file.\nrequired",
    "crumbs": [
      "Writers",
      "pickle_speakers"
    ]
  },
  {
    "objectID": "reference/pickle_speakers.html#parameters",
    "href": "reference/pickle_speakers.html#parameters",
    "title": "pickle_speakers",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nspeakers\nSpeakerCollection\nA SpeakerCollection to serialize\nrequired\n\n\npath\nstr | Path\nThe destination file to save the pickle file.\nrequired",
    "crumbs": [
      "Writers",
      "pickle_speakers"
    ]
  },
  {
    "objectID": "reference/fave_corpus.html",
    "href": "reference/fave_corpus.html",
    "title": "fave_corpus",
    "section": "",
    "text": "fave_corpus(corpus_path, speakers=0, include_overlaps=True, recode_rules=None, labelset_parser=None, point_heuristic=None, vowel_place_config=None, ft_config='default', reference_values=ReferenceValues(), fave_aligned=False)\nProcess a corpus directory.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ncorpus_path\nstr | Path\nPath to a corpus directory\nrequired\n\n\nspeakers\n(int, str, Path)\nWhich speaker(s) to produce data for. Can be a numeric index, or a path to a speaker file, or “all”\n0\n\n\ninclude_overlaps\nbool\nWhether or not to include vowels that are overlapped with speech from other tiers. Defaults to True.\nTrue\n\n\nrecode_rules\nstr | None\nEither a string naming built-in set of recode rules, or path to a custom ruleset. Defaults to None.\nNone\n\n\nlabelset_parser\nstr | None\nEither a string naming a built-in labelset parser, or a path to a custom parser definition. Defaults to None.\nNone\n\n\npoint_heuristic\nstr | None\nEither a string naming a built in point heuristic, or a path to a custom heuristic definition. Defaults to None.\nNone\n\n\nvowel_place_config\nstr | None)\nA path to a vowel place config file. defaults to None.\nNone\n\n\nft_config\nstr | None\nEither a string naming a built-in fasttrack config file, or a path to a custom config file. Defaults to “default”.\n'default'\n\n\nreference_values\nReferenceValues\nA ReferenceValues object defining a path to a reference corpus Defaults to ReferenceValues()\nReferenceValues()\n\n\nfave_aligned\nbool\nWere the textgrids generated by classic FAVE align? Defaults to False.\nFalse\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nSpeakerCollection\nA new_fave.SpeakerCollection",
    "crumbs": [
      "Processing Patterns",
      "fave_corpus"
    ]
  },
  {
    "objectID": "reference/fave_corpus.html#parameters",
    "href": "reference/fave_corpus.html#parameters",
    "title": "fave_corpus",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\ncorpus_path\nstr | Path\nPath to a corpus directory\nrequired\n\n\nspeakers\n(int, str, Path)\nWhich speaker(s) to produce data for. Can be a numeric index, or a path to a speaker file, or “all”\n0\n\n\ninclude_overlaps\nbool\nWhether or not to include vowels that are overlapped with speech from other tiers. Defaults to True.\nTrue\n\n\nrecode_rules\nstr | None\nEither a string naming built-in set of recode rules, or path to a custom ruleset. Defaults to None.\nNone\n\n\nlabelset_parser\nstr | None\nEither a string naming a built-in labelset parser, or a path to a custom parser definition. Defaults to None.\nNone\n\n\npoint_heuristic\nstr | None\nEither a string naming a built in point heuristic, or a path to a custom heuristic definition. Defaults to None.\nNone\n\n\nvowel_place_config\nstr | None)\nA path to a vowel place config file. defaults to None.\nNone\n\n\nft_config\nstr | None\nEither a string naming a built-in fasttrack config file, or a path to a custom config file. Defaults to “default”.\n'default'\n\n\nreference_values\nReferenceValues\nA ReferenceValues object defining a path to a reference corpus Defaults to ReferenceValues()\nReferenceValues()\n\n\nfave_aligned\nbool\nWere the textgrids generated by classic FAVE align? Defaults to False.\nFalse",
    "crumbs": [
      "Processing Patterns",
      "fave_corpus"
    ]
  },
  {
    "objectID": "reference/fave_corpus.html#returns",
    "href": "reference/fave_corpus.html#returns",
    "title": "fave_corpus",
    "section": "",
    "text": "Type\nDescription\n\n\n\n\nSpeakerCollection\nA new_fave.SpeakerCollection",
    "crumbs": [
      "Processing Patterns",
      "fave_corpus"
    ]
  },
  {
    "objectID": "reference/write_data.html",
    "href": "reference/write_data.html",
    "title": "write_data",
    "section": "",
    "text": "write_data(vowel_spaces, destination=Path('.'), which='all', separate=False)\nSave data.\n\n\nThere are multiple data output types, including\n\ntracks: Vowel formant tracks\npoints: Point measurements\nparam: DCT parameters on Hz\nlog_param: DCT parameters on log(Hz)\ntextgrid: The recoded textgrid\n\nBy default, they will all be saved.\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nvowel_spaces\nSpeakerCollection\nAn entire SpeakerCollection\nrequired\n\n\ndestination\nstr | Path\nDestination directory. Defaults to Path(\".\").\nPath('.')\n\n\nwhich\nLiteral[‘all’] | list[Literal[‘tracks’, ‘points’, ‘param’, ‘log_param’, ‘textgrid’]]\nWhich data to save. The values are described above. Defaults to “all”.\n'all'\n\n\nseparate\nbool\nWhether or not to write separate .csvs for each individual speaker. Defaults to False.\nFalse",
    "crumbs": [
      "Writers",
      "write_data"
    ]
  },
  {
    "objectID": "reference/write_data.html#parameters",
    "href": "reference/write_data.html#parameters",
    "title": "write_data",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nvowel_spaces\nSpeakerCollection\nAn entire SpeakerCollection\nrequired\n\n\ndestination\nstr | Path\nDestination directory. Defaults to Path(\".\").\nPath('.')\n\n\nwhich\nLiteral[‘all’] | list[Literal[‘tracks’, ‘points’, ‘param’, ‘log_param’, ‘textgrid’]]\nWhich data to save. The values are described above. Defaults to “all”.\n'all'\n\n\nseparate\nbool\nWhether or not to write separate .csvs for each individual speaker. Defaults to False.\nFalse",
    "crumbs": [
      "Writers",
      "write_data"
    ]
  },
  {
    "objectID": "reference/measurements.calcs.mahalanobis.html",
    "href": "reference/measurements.calcs.mahalanobis.html",
    "title": "measurements.calcs.mahalanobis",
    "section": "",
    "text": "measurements.calcs.mahalanobis(params, param_means, inv_cov)\nCalculates the Mahalanobis distance.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nparams\nNDArray[Shape[Dim, Cand], Float]\nThe parameters for which the Mahalanobis distance is to be calculated.\nrequired\n\n\nparam_means\nNDArray[Shape[Dim, 1], Float]\nThe mean of the distribution.\nrequired\n\n\ninv_cov\nNDArray[Shape[Dim, Dim], Float]\nThe inverse of the covariance matrix of the distribution.\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nNDArray[Shape[Cand], Float]\nThe Mahalanobis distance of each parameter from the distribution.",
    "crumbs": [
      "Calculations",
      "measurements.calcs.mahalanobis"
    ]
  },
  {
    "objectID": "reference/measurements.calcs.mahalanobis.html#parameters",
    "href": "reference/measurements.calcs.mahalanobis.html#parameters",
    "title": "measurements.calcs.mahalanobis",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nparams\nNDArray[Shape[Dim, Cand], Float]\nThe parameters for which the Mahalanobis distance is to be calculated.\nrequired\n\n\nparam_means\nNDArray[Shape[Dim, 1], Float]\nThe mean of the distribution.\nrequired\n\n\ninv_cov\nNDArray[Shape[Dim, Dim], Float]\nThe inverse of the covariance matrix of the distribution.\nrequired",
    "crumbs": [
      "Calculations",
      "measurements.calcs.mahalanobis"
    ]
  },
  {
    "objectID": "reference/measurements.calcs.mahalanobis.html#returns",
    "href": "reference/measurements.calcs.mahalanobis.html#returns",
    "title": "measurements.calcs.mahalanobis",
    "section": "",
    "text": "Type\nDescription\n\n\n\n\nNDArray[Shape[Cand], Float]\nThe Mahalanobis distance of each parameter from the distribution.",
    "crumbs": [
      "Calculations",
      "measurements.calcs.mahalanobis"
    ]
  },
  {
    "objectID": "reference/speaker.speaker.Speaker.html",
    "href": "reference/speaker.speaker.Speaker.html",
    "title": "speaker.speaker.Speaker",
    "section": "",
    "text": "speaker.speaker.Speaker(self, arg=None, file_name=None)\nThis is a class to represent speaker information. The argument to Speaker() can be one of\n\nA .yaml file\nA .csv file\nA .xlsx file\nAn old fave .speaker file\n\nWith the exception of the old .speaker files, to work well with new-fave, these speaker files should contain the following fields\n\nfile_name: The file stem of the wav and textgrid files\nspeaker_num: The speaker to be analyzed in a file. the first speaker is 1.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\ndf\npl.DataFrame\nA polars data frame of speaker information",
    "crumbs": [
      "Speaker files",
      "speaker.speaker.Speaker"
    ]
  },
  {
    "objectID": "reference/speaker.speaker.Speaker.html#attributes",
    "href": "reference/speaker.speaker.Speaker.html#attributes",
    "title": "speaker.speaker.Speaker",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\ndf\npl.DataFrame\nA polars data frame of speaker information",
    "crumbs": [
      "Speaker files",
      "speaker.speaker.Speaker"
    ]
  },
  {
    "objectID": "reference/VowelClass.html",
    "href": "reference/VowelClass.html",
    "title": "VowelClass",
    "section": "",
    "text": "VowelClass(self, label='', vowel_measurements=lambda: []())\nA class used to represent a vowel class.\n\n\nVowelClass subclasses collections.abc.Sequence, so it is indexable. While it can be created on its own, it is best to leave this up to either VowelClassCollection or SpeakerCollection.\nvowel_measurements = [VowelMeasurement(t) for t in fasttrack_tracks]\nvowel_class = VowelClass(\"ay\", vowel_measurements)\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nlabel\nstr\nThe vowel class label\n''\n\n\nvowel_measurements\nlist[VowelMeasurement]\nA list of VowelMeasurements\nlambda: []()\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\nlabel\nstr\nlabel of the vowel class\n\n\ntracks\nlist\nA list of VowelMeasurements\n\n\nvowel_system\nVowelClassCollection\nThe containing vowel system\n\n\nwinners\nlist[OneTrack]\nA list of winner OneTracks from the vowel class\n\n\nwinner_param\nNDArray[Shape[Param, Formant, N], Float]\nAn np.array of winner DCT parameters from the vowel class\n\n\nwinner_param_mean\nNDArray[Shape[ParamFormant, 1], Float]\nMean of winner DCT parameters\n\n\nwinner_param_cov\nNDArray[Shape[ParamFormant, ParamFormant], Float]\nCovariance of winner DCT parameters\n\n\nwinner_param_icov\nNDArray[Shape[ParamFormant, ParamFormant], Float]\nInverse covariance of winner DCT parameters\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nto_param_df\nReturn DataFrame of formant DCT parameters.\n\n\nto_point_df\nReturn a DataFrame of point measurements\n\n\nto_tracks_df\nReturn DataFrame of formanttracks.\n\n\n\n\n\nVowelClass.to_param_df(output='log_param')\nReturn DataFrame of formant DCT parameters.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npl.DataFrame\nA DataFrame of formant DCT parameters\n\n\n\n\n\n\n\nVowelClass.to_point_df()\nReturn a DataFrame of point measurements\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npl.DataFrame\nA DataFrame of vowel point measures.\n\n\n\n\n\n\n\nVowelClass.to_tracks_df()\nReturn DataFrame of formanttracks.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npl.DataFrame\nA DataFrame of formant tracks",
    "crumbs": [
      "Vowel Measurements",
      "VowelClass"
    ]
  },
  {
    "objectID": "reference/VowelClass.html#intended-usage",
    "href": "reference/VowelClass.html#intended-usage",
    "title": "VowelClass",
    "section": "",
    "text": "VowelClass subclasses collections.abc.Sequence, so it is indexable. While it can be created on its own, it is best to leave this up to either VowelClassCollection or SpeakerCollection.\nvowel_measurements = [VowelMeasurement(t) for t in fasttrack_tracks]\nvowel_class = VowelClass(\"ay\", vowel_measurements)",
    "crumbs": [
      "Vowel Measurements",
      "VowelClass"
    ]
  },
  {
    "objectID": "reference/VowelClass.html#parameters",
    "href": "reference/VowelClass.html#parameters",
    "title": "VowelClass",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nlabel\nstr\nThe vowel class label\n''\n\n\nvowel_measurements\nlist[VowelMeasurement]\nA list of VowelMeasurements\nlambda: []()",
    "crumbs": [
      "Vowel Measurements",
      "VowelClass"
    ]
  },
  {
    "objectID": "reference/VowelClass.html#attributes",
    "href": "reference/VowelClass.html#attributes",
    "title": "VowelClass",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\nlabel\nstr\nlabel of the vowel class\n\n\ntracks\nlist\nA list of VowelMeasurements\n\n\nvowel_system\nVowelClassCollection\nThe containing vowel system\n\n\nwinners\nlist[OneTrack]\nA list of winner OneTracks from the vowel class\n\n\nwinner_param\nNDArray[Shape[Param, Formant, N], Float]\nAn np.array of winner DCT parameters from the vowel class\n\n\nwinner_param_mean\nNDArray[Shape[ParamFormant, 1], Float]\nMean of winner DCT parameters\n\n\nwinner_param_cov\nNDArray[Shape[ParamFormant, ParamFormant], Float]\nCovariance of winner DCT parameters\n\n\nwinner_param_icov\nNDArray[Shape[ParamFormant, ParamFormant], Float]\nInverse covariance of winner DCT parameters",
    "crumbs": [
      "Vowel Measurements",
      "VowelClass"
    ]
  },
  {
    "objectID": "reference/VowelClass.html#methods",
    "href": "reference/VowelClass.html#methods",
    "title": "VowelClass",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nto_param_df\nReturn DataFrame of formant DCT parameters.\n\n\nto_point_df\nReturn a DataFrame of point measurements\n\n\nto_tracks_df\nReturn DataFrame of formanttracks.\n\n\n\n\n\nVowelClass.to_param_df(output='log_param')\nReturn DataFrame of formant DCT parameters.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npl.DataFrame\nA DataFrame of formant DCT parameters\n\n\n\n\n\n\n\nVowelClass.to_point_df()\nReturn a DataFrame of point measurements\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npl.DataFrame\nA DataFrame of vowel point measures.\n\n\n\n\n\n\n\nVowelClass.to_tracks_df()\nReturn DataFrame of formanttracks.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npl.DataFrame\nA DataFrame of formant tracks",
    "crumbs": [
      "Vowel Measurements",
      "VowelClass"
    ]
  },
  {
    "objectID": "reference/VowelMeasurement.html",
    "href": "reference/VowelMeasurement.html",
    "title": "VowelMeasurement",
    "section": "",
    "text": "VowelMeasurement(self, track, heuristic=Heuristic(), vowel_place_dict=lambda: dict()(), reference_values=ReferenceValues(), only_fasttrack=False)\nA class used to represent a vowel measurement.\n\n\nCertain properties of a VowelMeasurement instance are set by its membership within a VowelClass and that VowelClass’s membership in a VowelClassCollection. These memberships are best managed by passing a list of VowelMeasurements to SpeakerCollection.\nvowel_measurements = [VowelMeasurement(t) for t in fasttrack_tracks]\nspeakers = SpeakerCollection(vowel_measurements)\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ntrack\nfasttrackpy.CandidateTracks\nA fasttrackpy.CandidateTrracks object\nrequired\n\n\nheuristic\nHeuristic\nA point measurement Heuristic to use. Defaults to Heuristic().\nHeuristic()\n\n\nvowel_place_dict\ndict[Literal[‘front’, ‘back’], re.Pattern]\nA dictionary of regexes that match front or back vowels.\nlambda: dict()()\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\ntrack\nfasttrackpy.CandidateTracks\nan object of CandidateTracks class\n\n\ncandidates\nlist\nlist of candidates for the track\n\n\nheuristic\nHeuristic\nan object of Heuristic class (default is Heuristic())\n\n\nvowel_class\nVowelClass\nThe containing VowelClass object\n\n\nformant_array\nFormantArray\nA FormantArray object\n\n\nfile_name\nstr\nname of the file of the track\n\n\ngroup\nstr\nTierGroup of the track\n\n\nid\nstr\nid of the track\n\n\ninterval\naligned_textgrid.SequenceInterval\ninterval of the track\n\n\nlabel\nstr\nlabel of the track\n\n\nn_formants\nint\nnumber of formants in the track\n\n\noptimized\nint\nThe number of optimization iterations the vowel measurement has been through.\n\n\nwinner\nOneTrack\nfasttrackpy.OneTrack The winning formant track\n\n\nwinner_index\nint\nThe index of the winning formant track\n\n\ncand_param\nNDArray[Shape[Param, Formant, Cand], Float]\nA array of the candidate DCT parameters.\n\n\ncand_maxformant\nNDArray[Shape[1, Cand], Float]\nAn array of the candidate maximum formants.\n\n\ncand_error\nNDArray[Shape[Cand], Float]\nAn array of the candidate smoothing error.\n\n\ncand_error_logprob_vm\nNDArray[Shape[Cand], Float]\nConversion of the smooth error to log probabilities. The candidate with the lowest error = log(1), and the candidate with the largest error = log(0).\n\n\ncand_param_(mahal/logprob)_speaker_byvclass\nNDArray[Shape[Cand], Float]\nThe mahalanobis distance (mahal) or associated log probability (logprob) for each candidate relative to the VowelClass for this speaker. These are calculated by drawing the relevant mean and covariance matrix from vm.vowel_class\n\n\ncand_param_(mahal/logprob)_speaker_global\nNDArray[Shape[Cand], Float]\nThe mahalanobis distance (mahal) or associated log probability (logprob) for each candidate relative to all vowel measurements for this speaker. These are calculated by drawing the relevant mean and covariance matrix from vm.vowel_class.vowel_system\n\n\ncand_param_(mahal/logprob)_corpus_byvclass\nNDArray[Shape[Cand], Float]\nThe mahalanobis distance (mahal) or associated log probability (logprob) for each candidate relative to this vowel class across all speakers. These are calculated by drawing the relevant mean and covariance matrix from vm.vowel_class.vowel_system.corpus\n\n\npoint_measure\npl.DataFrame\nA polars dataframe of the point measurement for this vowel.\n\n\nvm_context\npl.DataFrame\nA polars dataframe of contextual information for the vowel measurement.\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nto_param_df\nReturn DataFrame of formant DCT parameters.\n\n\nto_point_df\nReturn a DataFrame of point measurements\n\n\nto_tracks_df\nReturn a DataFrame of the formant tracks\n\n\n\n\n\nVowelMeasurement.to_param_df(output='log_param')\nReturn DataFrame of formant DCT parameters.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npl.DataFrame\nA DataFrame of formant DCT parameters\n\n\n\n\n\n\n\nVowelMeasurement.to_point_df()\nReturn a DataFrame of point measurements\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npl.DataFrame\nA DataFrame of vowel point measures.\n\n\n\n\n\n\n\nVowelMeasurement.to_tracks_df()\nReturn a DataFrame of the formant tracks\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npl.DataFrame\nA dataframe with formant track data.",
    "crumbs": [
      "Vowel Measurements",
      "VowelMeasurement"
    ]
  },
  {
    "objectID": "reference/VowelMeasurement.html#intended-usage",
    "href": "reference/VowelMeasurement.html#intended-usage",
    "title": "VowelMeasurement",
    "section": "",
    "text": "Certain properties of a VowelMeasurement instance are set by its membership within a VowelClass and that VowelClass’s membership in a VowelClassCollection. These memberships are best managed by passing a list of VowelMeasurements to SpeakerCollection.\nvowel_measurements = [VowelMeasurement(t) for t in fasttrack_tracks]\nspeakers = SpeakerCollection(vowel_measurements)",
    "crumbs": [
      "Vowel Measurements",
      "VowelMeasurement"
    ]
  },
  {
    "objectID": "reference/VowelMeasurement.html#parameters",
    "href": "reference/VowelMeasurement.html#parameters",
    "title": "VowelMeasurement",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\ntrack\nfasttrackpy.CandidateTracks\nA fasttrackpy.CandidateTrracks object\nrequired\n\n\nheuristic\nHeuristic\nA point measurement Heuristic to use. Defaults to Heuristic().\nHeuristic()\n\n\nvowel_place_dict\ndict[Literal[‘front’, ‘back’], re.Pattern]\nA dictionary of regexes that match front or back vowels.\nlambda: dict()()",
    "crumbs": [
      "Vowel Measurements",
      "VowelMeasurement"
    ]
  },
  {
    "objectID": "reference/VowelMeasurement.html#attributes",
    "href": "reference/VowelMeasurement.html#attributes",
    "title": "VowelMeasurement",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\ntrack\nfasttrackpy.CandidateTracks\nan object of CandidateTracks class\n\n\ncandidates\nlist\nlist of candidates for the track\n\n\nheuristic\nHeuristic\nan object of Heuristic class (default is Heuristic())\n\n\nvowel_class\nVowelClass\nThe containing VowelClass object\n\n\nformant_array\nFormantArray\nA FormantArray object\n\n\nfile_name\nstr\nname of the file of the track\n\n\ngroup\nstr\nTierGroup of the track\n\n\nid\nstr\nid of the track\n\n\ninterval\naligned_textgrid.SequenceInterval\ninterval of the track\n\n\nlabel\nstr\nlabel of the track\n\n\nn_formants\nint\nnumber of formants in the track\n\n\noptimized\nint\nThe number of optimization iterations the vowel measurement has been through.\n\n\nwinner\nOneTrack\nfasttrackpy.OneTrack The winning formant track\n\n\nwinner_index\nint\nThe index of the winning formant track\n\n\ncand_param\nNDArray[Shape[Param, Formant, Cand], Float]\nA array of the candidate DCT parameters.\n\n\ncand_maxformant\nNDArray[Shape[1, Cand], Float]\nAn array of the candidate maximum formants.\n\n\ncand_error\nNDArray[Shape[Cand], Float]\nAn array of the candidate smoothing error.\n\n\ncand_error_logprob_vm\nNDArray[Shape[Cand], Float]\nConversion of the smooth error to log probabilities. The candidate with the lowest error = log(1), and the candidate with the largest error = log(0).\n\n\ncand_param_(mahal/logprob)_speaker_byvclass\nNDArray[Shape[Cand], Float]\nThe mahalanobis distance (mahal) or associated log probability (logprob) for each candidate relative to the VowelClass for this speaker. These are calculated by drawing the relevant mean and covariance matrix from vm.vowel_class\n\n\ncand_param_(mahal/logprob)_speaker_global\nNDArray[Shape[Cand], Float]\nThe mahalanobis distance (mahal) or associated log probability (logprob) for each candidate relative to all vowel measurements for this speaker. These are calculated by drawing the relevant mean and covariance matrix from vm.vowel_class.vowel_system\n\n\ncand_param_(mahal/logprob)_corpus_byvclass\nNDArray[Shape[Cand], Float]\nThe mahalanobis distance (mahal) or associated log probability (logprob) for each candidate relative to this vowel class across all speakers. These are calculated by drawing the relevant mean and covariance matrix from vm.vowel_class.vowel_system.corpus\n\n\npoint_measure\npl.DataFrame\nA polars dataframe of the point measurement for this vowel.\n\n\nvm_context\npl.DataFrame\nA polars dataframe of contextual information for the vowel measurement.",
    "crumbs": [
      "Vowel Measurements",
      "VowelMeasurement"
    ]
  },
  {
    "objectID": "reference/VowelMeasurement.html#methods",
    "href": "reference/VowelMeasurement.html#methods",
    "title": "VowelMeasurement",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nto_param_df\nReturn DataFrame of formant DCT parameters.\n\n\nto_point_df\nReturn a DataFrame of point measurements\n\n\nto_tracks_df\nReturn a DataFrame of the formant tracks\n\n\n\n\n\nVowelMeasurement.to_param_df(output='log_param')\nReturn DataFrame of formant DCT parameters.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npl.DataFrame\nA DataFrame of formant DCT parameters\n\n\n\n\n\n\n\nVowelMeasurement.to_point_df()\nReturn a DataFrame of point measurements\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npl.DataFrame\nA DataFrame of vowel point measures.\n\n\n\n\n\n\n\nVowelMeasurement.to_tracks_df()\nReturn a DataFrame of the formant tracks\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npl.DataFrame\nA dataframe with formant track data.",
    "crumbs": [
      "Vowel Measurements",
      "VowelMeasurement"
    ]
  },
  {
    "objectID": "reference/VowelClassCollection.html",
    "href": "reference/VowelClassCollection.html",
    "title": "VowelClassCollection",
    "section": "",
    "text": "VowelClassCollection(self, track_list=EMPTY_LIST)\nA class for an entire vowel system.\n\n\nIt is a subclass of defaultdict, so it can be keyed by vowel class label.\nvowel_measurements = [VowelMeasurement(t) for t in fasttrack_tracks]\nvowel_system = VowelClassCollection(vowel_measurements)\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ntrack_list\nlist[VowelMeasurement]\nA list of VowelMeasurements.\nEMPTY_LIST\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\nwinners\nlist[OneTrack]\nAll winner tracks from the entire vowel system.\n\n\nvowel_measurements\nlist[VowelMeasurement]\nAll VowelMeasurement objects within this vowel system\n\n\ntextgrid\nAlignedTextGrid\nThe AlignedTextGrid associated with this vowel system.\n\n\nwinner_expanded_formants\nNDArray[Shape[20, FormantN], Float]\nA cached property that returns the expanded formants for the winners.\n\n\nwinner_param\nNDArray[Shape[Param, Formant, N], Float]\nAn array of all parameters from all winners across the vowel system.\n\n\nwinner_maxformant\nNDArray[Shape[1, N], Float]\nAn array of the maximum formants of all winners across the vowel system\n\n\nwinner_param_mean\nNDArray[Shape[1, FormantParam], Float]\nThe mean of all DCT parameters across all formants for the winners in this vowel system.\n\n\nwinner_param_cov\nNDArray[Shape[FormantParam, FormantParam], Float]\nThe covariance of all parameters across all formants for the winners in this vowel system\n\n\nwinner_param_icov\nNDArray[Shape[FormantParam, FormantParam], Float]\nThe inverse of winner_param_cov.\n\n\nwinner_maxformant_mean\nfloat\nThe mean maximum formant across all winners in this vowel system.\n\n\nwinner_maxformant_cov\nNDArray[Shape[1, 1], Float]\nThe covariance of the maximum formant across all winners in this vowel system.\n\n\nwinner_maxformant_icov\nNDArray[Shape[1, 1], Float]\nThe inverse of winner_maxformant_cov\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nedge_intercept\nReturn the intercept for a line with the given slope\n\n\nto_param_df\nReturn DataFrame of formant DCT parameters.\n\n\nto_point_df\nReturn a DataFrame of point measurements\n\n\nto_tracks_df\nReturn a DataFrame of the formant tracks\n\n\n\n\n\nVowelClassCollection.edge_intercept(slope=-1.5)\nReturn the intercept for a line with the given slope such that it will intersect with x=y above the center of the vowel space\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nslope\nfloat\nThe slope of the line. Defaults to -1.5\n-1.5\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nnp.ndarray\nThe intercept\n\n\n\n\n\n\n\nVowelClassCollection.to_param_df(output='log_param')\nReturn DataFrame of formant DCT parameters.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npl.DataFrame\nA DataFrame of formant DCT parameters\n\n\n\n\n\n\n\nVowelClassCollection.to_point_df()\nReturn a DataFrame of point measurements\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npl.DataFrame\nA DataFrame of vowel point measures.\n\n\n\n\n\n\n\nVowelClassCollection.to_tracks_df()\nReturn a DataFrame of the formant tracks\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npl.DataFrame\nA dataframe with formant track data.",
    "crumbs": [
      "Vowel Measurements",
      "VowelClassCollection"
    ]
  },
  {
    "objectID": "reference/VowelClassCollection.html#intended-usage",
    "href": "reference/VowelClassCollection.html#intended-usage",
    "title": "VowelClassCollection",
    "section": "",
    "text": "It is a subclass of defaultdict, so it can be keyed by vowel class label.\nvowel_measurements = [VowelMeasurement(t) for t in fasttrack_tracks]\nvowel_system = VowelClassCollection(vowel_measurements)",
    "crumbs": [
      "Vowel Measurements",
      "VowelClassCollection"
    ]
  },
  {
    "objectID": "reference/VowelClassCollection.html#parameters",
    "href": "reference/VowelClassCollection.html#parameters",
    "title": "VowelClassCollection",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\ntrack_list\nlist[VowelMeasurement]\nA list of VowelMeasurements.\nEMPTY_LIST",
    "crumbs": [
      "Vowel Measurements",
      "VowelClassCollection"
    ]
  },
  {
    "objectID": "reference/VowelClassCollection.html#attributes",
    "href": "reference/VowelClassCollection.html#attributes",
    "title": "VowelClassCollection",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\nwinners\nlist[OneTrack]\nAll winner tracks from the entire vowel system.\n\n\nvowel_measurements\nlist[VowelMeasurement]\nAll VowelMeasurement objects within this vowel system\n\n\ntextgrid\nAlignedTextGrid\nThe AlignedTextGrid associated with this vowel system.\n\n\nwinner_expanded_formants\nNDArray[Shape[20, FormantN], Float]\nA cached property that returns the expanded formants for the winners.\n\n\nwinner_param\nNDArray[Shape[Param, Formant, N], Float]\nAn array of all parameters from all winners across the vowel system.\n\n\nwinner_maxformant\nNDArray[Shape[1, N], Float]\nAn array of the maximum formants of all winners across the vowel system\n\n\nwinner_param_mean\nNDArray[Shape[1, FormantParam], Float]\nThe mean of all DCT parameters across all formants for the winners in this vowel system.\n\n\nwinner_param_cov\nNDArray[Shape[FormantParam, FormantParam], Float]\nThe covariance of all parameters across all formants for the winners in this vowel system\n\n\nwinner_param_icov\nNDArray[Shape[FormantParam, FormantParam], Float]\nThe inverse of winner_param_cov.\n\n\nwinner_maxformant_mean\nfloat\nThe mean maximum formant across all winners in this vowel system.\n\n\nwinner_maxformant_cov\nNDArray[Shape[1, 1], Float]\nThe covariance of the maximum formant across all winners in this vowel system.\n\n\nwinner_maxformant_icov\nNDArray[Shape[1, 1], Float]\nThe inverse of winner_maxformant_cov",
    "crumbs": [
      "Vowel Measurements",
      "VowelClassCollection"
    ]
  },
  {
    "objectID": "reference/VowelClassCollection.html#methods",
    "href": "reference/VowelClassCollection.html#methods",
    "title": "VowelClassCollection",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nedge_intercept\nReturn the intercept for a line with the given slope\n\n\nto_param_df\nReturn DataFrame of formant DCT parameters.\n\n\nto_point_df\nReturn a DataFrame of point measurements\n\n\nto_tracks_df\nReturn a DataFrame of the formant tracks\n\n\n\n\n\nVowelClassCollection.edge_intercept(slope=-1.5)\nReturn the intercept for a line with the given slope such that it will intersect with x=y above the center of the vowel space\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nslope\nfloat\nThe slope of the line. Defaults to -1.5\n-1.5\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nnp.ndarray\nThe intercept\n\n\n\n\n\n\n\nVowelClassCollection.to_param_df(output='log_param')\nReturn DataFrame of formant DCT parameters.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npl.DataFrame\nA DataFrame of formant DCT parameters\n\n\n\n\n\n\n\nVowelClassCollection.to_point_df()\nReturn a DataFrame of point measurements\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npl.DataFrame\nA DataFrame of vowel point measures.\n\n\n\n\n\n\n\nVowelClassCollection.to_tracks_df()\nReturn a DataFrame of the formant tracks\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npl.DataFrame\nA dataframe with formant track data.",
    "crumbs": [
      "Vowel Measurements",
      "VowelClassCollection"
    ]
  },
  {
    "objectID": "reference/measurements.vowel_measurement.html",
    "href": "reference/measurements.vowel_measurement.html",
    "title": "measurements.vowel_measurement",
    "section": "",
    "text": "measurements.vowel_measurement\nThis module contains classes to represent vowel measurements and their aggregations at different levels.\n\n\n\n\n\nclassDiagram\ndirection LR\n\nclass VowelMeasurement~list~{\n    .vowel_class\n}\nclass VowelClass~list~{\n    .vowel_system\n}\nclass VowelClassCollection~dict~{\n    .corpus\n}\nclass SpeakerCollection~dict~\n\nSpeakerCollection --o VowelClassCollection\nVowelClassCollection --o VowelClass\nVowelClass --o VowelMeasurement\n\n\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nnew_fave.measurements.vowel_measurement.PropertySetter\nA mixin class to dynamically create properties\n\n\nnew_fave.measurements.vowel_measurement.SpeakerCollection\nA class to represent the vowel system of all\n\n\nnew_fave.measurements.vowel_measurement.VowelClass\nA class used to represent a vowel class.\n\n\nnew_fave.measurements.vowel_measurement.VowelClassCollection\nA class for an entire vowel system.\n\n\nnew_fave.measurements.vowel_measurement.VowelMeasurement\nA class used to represent a vowel measurement.",
    "crumbs": [
      "Vowel Measurements",
      "measurements.vowel_measurement"
    ]
  },
  {
    "objectID": "reference/measurements.vowel_measurement.html#classes",
    "href": "reference/measurements.vowel_measurement.html#classes",
    "title": "measurements.vowel_measurement",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nnew_fave.measurements.vowel_measurement.PropertySetter\nA mixin class to dynamically create properties\n\n\nnew_fave.measurements.vowel_measurement.SpeakerCollection\nA class to represent the vowel system of all\n\n\nnew_fave.measurements.vowel_measurement.VowelClass\nA class used to represent a vowel class.\n\n\nnew_fave.measurements.vowel_measurement.VowelClassCollection\nA class for an entire vowel system.\n\n\nnew_fave.measurements.vowel_measurement.VowelMeasurement\nA class used to represent a vowel measurement.",
    "crumbs": [
      "Vowel Measurements",
      "measurements.vowel_measurement"
    ]
  },
  {
    "objectID": "reference/optimize.optimize.html",
    "href": "reference/optimize.optimize.html",
    "title": "optimize.optimize",
    "section": "",
    "text": "optimize.optimize\n\n\n\n\n\nName\nDescription\n\n\n\n\noptimize_one_measure\nOptimize a single vowel measurement\n\n\noptimize_vowel_measures\nOptimize a list of VowelMeasurements.\n\n\nrun_optimize\nRepeatedly run optimization until either max_iter is reached,\n\n\n\n\n\noptimize.optimize.optimize_one_measure(vowel_measurement, optim_params, f1_cutoff=np.inf, f2_cutoff=np.inf)\nOptimize a single vowel measurement\nThis function optimizes a given vowel measurement based on the specified optimization parameters.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nvowel_measurement\nVowelMeasurement\nThe VowelMeasurement to optimize\nrequired\n\n\noptim_params\nlist[Literal[‘param_speaker_global’, ‘param_speaker_byvclass’, ‘bparam_speaker_global’, ‘bparam_speaker_byvclass’, ‘maxformant_speaker_global’, ‘param_corpus_byvowel’]]\nThe optimization parameters to use. Defaults to [ “param_speaker_global”, “param_speaker_byvclass”, “bparam_speaker_global”, “bparam_speaker_byvclass”, “maxformant_speaker_global” ].\nrequired\n\n\nf1_cutoff\nfloat | np.float64\nThe maximum considerable F1 value\nnp.inf\n\n\nf2_cutoff\nfloat | np.float64\nThe maximum considerable F2 value\nnp.inf\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nint\ndescription\n\n\n\n\n\n\n\noptimize.optimize.optimize_vowel_measures(vowel_measurements, optim_params, f1_cutoff=np.inf, f2_cutoff=np.inf, pbar=None)\nOptimize a list of VowelMeasurements.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nvowel_measurements\nlist[VowelMeasurement]\nThe list of vowel measurements to optimize\nrequired\n\n\noptim_params\nlist[Literal[‘param_speaker_global’, ‘param_speaker_byvclass’, ‘bparam_speaker_global’, ‘bparam_speaker_byvclass’, ‘maxformant_speaker_global’, ‘param_corpus_byvowel’]]\nThe optimization parameters to use. Defaults to [ “param_speaker_global”, “param_speaker_byvclass”, “bparam_speaker_global”, “bparam_speaker_byvclass”, “maxformant_speaker_global” ].\nrequired\n\n\nf1_cutoff\nfloat | np.float64\nThe maximum considerable F1 value\nnp.inf\n\n\nf2_cutoff\nfloat | np.float64\nThe maximum considerable F2 value\nnp.inf\n\n\npbar\ntqdm\nA progress bar.\nNone\n\n\n\n\n\n\n\noptimize.optimize.run_optimize(vowel_system, optim_params=['param_speaker', 'centroid_speaker', 'maxformant_speaker'], f1_cutoff=np.inf, f2_cutoff=np.inf, max_iter=10)\nRepeatedly run optimization until either max_iter is reached, or the difference between two iterations becomes small.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nvowel_system\nVowelClassCollection\nThe vowel space to be optimized\nrequired\n\n\noptim_params\nlist[Literal[‘param_speaker_global’, ‘param_speaker_byvclass’, ‘bparam_speaker_global’, ‘bparam_speaker_byvclass’, ‘maxformant_speaker_global’, ‘param_corpus_byvowel’]]\nThe optimization parameters to use. Defaults to [ “param_speaker_global”, “param_speaker_byvclass”, “bparam_speaker_global”, “bparam_speaker_byvclass”, “maxformant_speaker_global” ].\n['param_speaker', 'centroid_speaker', 'maxformant_speaker']\n\n\nf1_cutoff\nfloat | np.float64\nThe maximum considerable F1 value\nnp.inf\n\n\nf2_cutoff\nfloat | np.float64\nThe maximum considerable F2 value\nnp.inf\n\n\nmax_iter\nint\nThe maximum number of iterations to run. Defaults to 10.\n10",
    "crumbs": [
      "Optimization",
      "optimize.optimize"
    ]
  },
  {
    "objectID": "reference/optimize.optimize.html#functions",
    "href": "reference/optimize.optimize.html#functions",
    "title": "optimize.optimize",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\noptimize_one_measure\nOptimize a single vowel measurement\n\n\noptimize_vowel_measures\nOptimize a list of VowelMeasurements.\n\n\nrun_optimize\nRepeatedly run optimization until either max_iter is reached,\n\n\n\n\n\noptimize.optimize.optimize_one_measure(vowel_measurement, optim_params, f1_cutoff=np.inf, f2_cutoff=np.inf)\nOptimize a single vowel measurement\nThis function optimizes a given vowel measurement based on the specified optimization parameters.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nvowel_measurement\nVowelMeasurement\nThe VowelMeasurement to optimize\nrequired\n\n\noptim_params\nlist[Literal[‘param_speaker_global’, ‘param_speaker_byvclass’, ‘bparam_speaker_global’, ‘bparam_speaker_byvclass’, ‘maxformant_speaker_global’, ‘param_corpus_byvowel’]]\nThe optimization parameters to use. Defaults to [ “param_speaker_global”, “param_speaker_byvclass”, “bparam_speaker_global”, “bparam_speaker_byvclass”, “maxformant_speaker_global” ].\nrequired\n\n\nf1_cutoff\nfloat | np.float64\nThe maximum considerable F1 value\nnp.inf\n\n\nf2_cutoff\nfloat | np.float64\nThe maximum considerable F2 value\nnp.inf\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nint\ndescription\n\n\n\n\n\n\n\noptimize.optimize.optimize_vowel_measures(vowel_measurements, optim_params, f1_cutoff=np.inf, f2_cutoff=np.inf, pbar=None)\nOptimize a list of VowelMeasurements.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nvowel_measurements\nlist[VowelMeasurement]\nThe list of vowel measurements to optimize\nrequired\n\n\noptim_params\nlist[Literal[‘param_speaker_global’, ‘param_speaker_byvclass’, ‘bparam_speaker_global’, ‘bparam_speaker_byvclass’, ‘maxformant_speaker_global’, ‘param_corpus_byvowel’]]\nThe optimization parameters to use. Defaults to [ “param_speaker_global”, “param_speaker_byvclass”, “bparam_speaker_global”, “bparam_speaker_byvclass”, “maxformant_speaker_global” ].\nrequired\n\n\nf1_cutoff\nfloat | np.float64\nThe maximum considerable F1 value\nnp.inf\n\n\nf2_cutoff\nfloat | np.float64\nThe maximum considerable F2 value\nnp.inf\n\n\npbar\ntqdm\nA progress bar.\nNone\n\n\n\n\n\n\n\noptimize.optimize.run_optimize(vowel_system, optim_params=['param_speaker', 'centroid_speaker', 'maxformant_speaker'], f1_cutoff=np.inf, f2_cutoff=np.inf, max_iter=10)\nRepeatedly run optimization until either max_iter is reached, or the difference between two iterations becomes small.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nvowel_system\nVowelClassCollection\nThe vowel space to be optimized\nrequired\n\n\noptim_params\nlist[Literal[‘param_speaker_global’, ‘param_speaker_byvclass’, ‘bparam_speaker_global’, ‘bparam_speaker_byvclass’, ‘maxformant_speaker_global’, ‘param_corpus_byvowel’]]\nThe optimization parameters to use. Defaults to [ “param_speaker_global”, “param_speaker_byvclass”, “bparam_speaker_global”, “bparam_speaker_byvclass”, “maxformant_speaker_global” ].\n['param_speaker', 'centroid_speaker', 'maxformant_speaker']\n\n\nf1_cutoff\nfloat | np.float64\nThe maximum considerable F1 value\nnp.inf\n\n\nf2_cutoff\nfloat | np.float64\nThe maximum considerable F2 value\nnp.inf\n\n\nmax_iter\nint\nThe maximum number of iterations to run. Defaults to 10.\n10",
    "crumbs": [
      "Optimization",
      "optimize.optimize"
    ]
  },
  {
    "objectID": "reference/unpickle_speakers.html",
    "href": "reference/unpickle_speakers.html",
    "title": "unpickle_speakers",
    "section": "",
    "text": "unpickle_speakers(path)\nUnpickle a pickled SpeakerCollection\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\npath\nstr | Path\nPath to a pickled speaker collection\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nSpeakerCollection\nThe unpickled SpeakerCollection",
    "crumbs": [
      "Writers",
      "unpickle_speakers"
    ]
  },
  {
    "objectID": "reference/unpickle_speakers.html#parameters",
    "href": "reference/unpickle_speakers.html#parameters",
    "title": "unpickle_speakers",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\npath\nstr | Path\nPath to a pickled speaker collection\nrequired",
    "crumbs": [
      "Writers",
      "unpickle_speakers"
    ]
  },
  {
    "objectID": "reference/unpickle_speakers.html#returns",
    "href": "reference/unpickle_speakers.html#returns",
    "title": "unpickle_speakers",
    "section": "",
    "text": "Type\nDescription\n\n\n\n\nSpeakerCollection\nThe unpickled SpeakerCollection",
    "crumbs": [
      "Writers",
      "unpickle_speakers"
    ]
  },
  {
    "objectID": "reference/optimize.left_edge.html",
    "href": "reference/optimize.left_edge.html",
    "title": "optimize.left_edge",
    "section": "",
    "text": "optimize.left_edge\n\n\n\n\n\nName\nDescription\n\n\n\n\nbeyond_edge\nFor a given vowel measurement, return an\n\n\n\n\n\noptimize.left_edge.beyond_edge(vowel_measurement)\nFor a given vowel measurement, return an array of log probabilities indicating whether or not a candidate is beyond the desired edge of the front of the vowel space.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nvowel_measurement\nVowelMeasurement\nA vowel measurement to optimize\nrequired\n\n\nslope\nfloat\nThe desired slope for the maximum edge of front vowel space. Defaults to -1.5.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nnp.ndarray\nnp.ndarray: log probabilities of 0 for candidates below the threshold, and negative infinity for candidates above it.",
    "crumbs": [
      "Optimization",
      "optimize.left_edge"
    ]
  },
  {
    "objectID": "reference/optimize.left_edge.html#functions",
    "href": "reference/optimize.left_edge.html#functions",
    "title": "optimize.left_edge",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nbeyond_edge\nFor a given vowel measurement, return an\n\n\n\n\n\noptimize.left_edge.beyond_edge(vowel_measurement)\nFor a given vowel measurement, return an array of log probabilities indicating whether or not a candidate is beyond the desired edge of the front of the vowel space.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nvowel_measurement\nVowelMeasurement\nA vowel measurement to optimize\nrequired\n\n\nslope\nfloat\nThe desired slope for the maximum edge of front vowel space. Defaults to -1.5.\nrequired\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nnp.ndarray\nnp.ndarray: log probabilities of 0 for candidates below the threshold, and negative infinity for candidates above it.",
    "crumbs": [
      "Optimization",
      "optimize.left_edge"
    ]
  },
  {
    "objectID": "reference/fave_subcorpora.html",
    "href": "reference/fave_subcorpora.html",
    "title": "fave_subcorpora",
    "section": "",
    "text": "fave_subcorpora(subcorpora_glob, speakers=0, speakers_glob=None, include_overlaps=True, recode_rules=None, labelset_parser=None, point_heuristic=None, vowel_place_config=None, ft_config='default', reference_values=ReferenceValues(), fave_aligned=False)\nProcess multiple subcorpora\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsubcorpora_glob\nstr | Path\nGlob to subcorpora\nrequired\n\n\nspeakers\n(int, str, Path)\nWhich speaker(s) to produce data for. Can be a numeric index, or a path to a speaker file, or “all”\n0\n\n\nspeakers_glob\nstr\nAlternatively to speakers, a file glob to speaker files.\nNone\n\n\ninclude_overlaps\nbool\nWhether or not to include vowels that are overlapped with speech from other tiers. Defaults to True.\nTrue\n\n\nrecode_rules\nstr | None\nEither a string naming built-in set of recode rules, or path to a custom ruleset. Defaults to None.\nNone\n\n\nlabelset_parser\nstr | None\nEither a string naming a built-in labelset parser, or a path to a custom parser definition. Defaults to None.\nNone\n\n\npoint_heuristic\nstr | None\nEither a string naming a built in point heuristic, or a path to a custom heuristic definition. Defaults to None.\nNone\n\n\nft_config\nstr | None\nEither a string naming a built-in fasttrack config file, or a path to a custom config file. Defaults to “default”.\n'default'\n\n\nvowel_place_config\nstr | None)\nA path to a vowel place config file. defaults to None.\nNone\n\n\nreference_values\nReferenceValues\nA ReferenceValues object defining a path to a reference corpus’ Defaults to ReferenceValues()\nReferenceValues()\n\n\nfave_aligned\nbool\nWere the textgrids generated by classic FAVE align? Defaults to False.\nFalse\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nSpeakerCollection\nA new_fave.SpeakerCollection",
    "crumbs": [
      "Processing Patterns",
      "fave_subcorpora"
    ]
  },
  {
    "objectID": "reference/fave_subcorpora.html#parameters",
    "href": "reference/fave_subcorpora.html#parameters",
    "title": "fave_subcorpora",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nsubcorpora_glob\nstr | Path\nGlob to subcorpora\nrequired\n\n\nspeakers\n(int, str, Path)\nWhich speaker(s) to produce data for. Can be a numeric index, or a path to a speaker file, or “all”\n0\n\n\nspeakers_glob\nstr\nAlternatively to speakers, a file glob to speaker files.\nNone\n\n\ninclude_overlaps\nbool\nWhether or not to include vowels that are overlapped with speech from other tiers. Defaults to True.\nTrue\n\n\nrecode_rules\nstr | None\nEither a string naming built-in set of recode rules, or path to a custom ruleset. Defaults to None.\nNone\n\n\nlabelset_parser\nstr | None\nEither a string naming a built-in labelset parser, or a path to a custom parser definition. Defaults to None.\nNone\n\n\npoint_heuristic\nstr | None\nEither a string naming a built in point heuristic, or a path to a custom heuristic definition. Defaults to None.\nNone\n\n\nft_config\nstr | None\nEither a string naming a built-in fasttrack config file, or a path to a custom config file. Defaults to “default”.\n'default'\n\n\nvowel_place_config\nstr | None)\nA path to a vowel place config file. defaults to None.\nNone\n\n\nreference_values\nReferenceValues\nA ReferenceValues object defining a path to a reference corpus’ Defaults to ReferenceValues()\nReferenceValues()\n\n\nfave_aligned\nbool\nWere the textgrids generated by classic FAVE align? Defaults to False.\nFalse",
    "crumbs": [
      "Processing Patterns",
      "fave_subcorpora"
    ]
  },
  {
    "objectID": "reference/fave_subcorpora.html#returns",
    "href": "reference/fave_subcorpora.html#returns",
    "title": "fave_subcorpora",
    "section": "",
    "text": "Type\nDescription\n\n\n\n\nSpeakerCollection\nA new_fave.SpeakerCollection",
    "crumbs": [
      "Processing Patterns",
      "fave_subcorpora"
    ]
  },
  {
    "objectID": "reference/fave_audio_textgrid.html",
    "href": "reference/fave_audio_textgrid.html",
    "title": "fave_audio_textgrid",
    "section": "",
    "text": "fave_audio_textgrid(audio_path, textgrid_path, speakers=0, include_overlaps=True, no_optimize=False, recode_rules=None, add_rules=None, labelset_parser=None, point_heuristic=None, vowel_place_config=None, f1_cutoff=np.inf, f2_cutoff=np.inf, ft_config='default', reference_values=ReferenceValues(), fave_aligned=False)\nProcess a single audio/textgrid pair.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\naudio_path\nstr | Path\nPath to an audio file\nrequired\n\n\ntextgrid_path\nstr | Path\nPath to a textgrid\nrequired\n\n\nspeakers\nint | list[int] | str | Path | optional\nWhich speaker(s) to produce data for. Can be a numeric index, or a path to a speaker file, or “all”\n0\n\n\ninclude_overlaps\nbool\nWhether or not to include vowels that are overlapped with speech from other tiers. Defaults to True.\nTrue\n\n\nrecode_rules\nstr | None\nEither a string naming built-in set of recode rules, or path to a custom ruleset. Defaults to None.\nNone\n\n\nlabelset_parser\nstr | None\nEither a string naming a built-in labelset parser, or a path to a custom parser definition. Defaults to None.\nNone\n\n\npoint_heuristic\nstr | None\nEither a string naming a built in point heuristic, or a path to a custom heuristic definition. Defaults to None.\nNone\n\n\nvowel_place_config\nstr | None)\nA path to a vowel place config file. defaults to None.\nNone\n\n\nf1_cutoff\nfloat | np.float64\nThe maximum considerable F1 value\nnp.inf\n\n\nf2_cutoff\nfloat | np.float64\nThe maximum considerable F2 value\nnp.inf\n\n\nft_config\nstr | None\nEither a string naming a built-in fasttrack config file, or a path to a custom config file. Defaults to “default”.\n'default'\n\n\nreference_values\nReferenceValues\nA ReferenceValues object defining a path to a reference corpus Defaults to ReferenceValues()\nReferenceValues()\n\n\nfave_aligned\nbool\nWere the textgrids generated by classic FAVE align? Defaults to False.\nFalse\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\nSpeakerCollection\nA new_fave.SpeakerCollection",
    "crumbs": [
      "Processing Patterns",
      "fave_audio_textgrid"
    ]
  },
  {
    "objectID": "reference/fave_audio_textgrid.html#parameters",
    "href": "reference/fave_audio_textgrid.html#parameters",
    "title": "fave_audio_textgrid",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\naudio_path\nstr | Path\nPath to an audio file\nrequired\n\n\ntextgrid_path\nstr | Path\nPath to a textgrid\nrequired\n\n\nspeakers\nint | list[int] | str | Path | optional\nWhich speaker(s) to produce data for. Can be a numeric index, or a path to a speaker file, or “all”\n0\n\n\ninclude_overlaps\nbool\nWhether or not to include vowels that are overlapped with speech from other tiers. Defaults to True.\nTrue\n\n\nrecode_rules\nstr | None\nEither a string naming built-in set of recode rules, or path to a custom ruleset. Defaults to None.\nNone\n\n\nlabelset_parser\nstr | None\nEither a string naming a built-in labelset parser, or a path to a custom parser definition. Defaults to None.\nNone\n\n\npoint_heuristic\nstr | None\nEither a string naming a built in point heuristic, or a path to a custom heuristic definition. Defaults to None.\nNone\n\n\nvowel_place_config\nstr | None)\nA path to a vowel place config file. defaults to None.\nNone\n\n\nf1_cutoff\nfloat | np.float64\nThe maximum considerable F1 value\nnp.inf\n\n\nf2_cutoff\nfloat | np.float64\nThe maximum considerable F2 value\nnp.inf\n\n\nft_config\nstr | None\nEither a string naming a built-in fasttrack config file, or a path to a custom config file. Defaults to “default”.\n'default'\n\n\nreference_values\nReferenceValues\nA ReferenceValues object defining a path to a reference corpus Defaults to ReferenceValues()\nReferenceValues()\n\n\nfave_aligned\nbool\nWere the textgrids generated by classic FAVE align? Defaults to False.\nFalse",
    "crumbs": [
      "Processing Patterns",
      "fave_audio_textgrid"
    ]
  },
  {
    "objectID": "reference/fave_audio_textgrid.html#returns",
    "href": "reference/fave_audio_textgrid.html#returns",
    "title": "fave_audio_textgrid",
    "section": "",
    "text": "Type\nDescription\n\n\n\n\nSpeakerCollection\nA new_fave.SpeakerCollection",
    "crumbs": [
      "Processing Patterns",
      "fave_audio_textgrid"
    ]
  },
  {
    "objectID": "reference/index.html",
    "href": "reference/index.html",
    "title": "Function reference",
    "section": "",
    "text": "Different patterns for processing data\n\n\n\nfave_audio_textgrid\nProcess a single audio/textgrid pair.\n\n\nfave_corpus\nProcess a corpus directory.\n\n\nfave_subcorpora\nProcess multiple subcorpora\n\n\n\n\n\n\n\n\n\nmeasurements.vowel_measurement\nThis module contains classes to represent vowel measurements and their\n\n\nVowelMeasurement\nA class used to represent a vowel measurement.\n\n\nVowelClass\nA class used to represent a vowel class.\n\n\nVowelClassCollection\nA class for an entire vowel system.\n\n\nSpeakerCollection\nA class to represent the vowel system of all\n\n\n\n\n\n\n\n\n\nmeasurements.calcs.mahalanobis\nCalculates the Mahalanobis distance.\n\n\n\n\n\n\nFunctions for optimizing formant measurements\n\n\n\noptimize.optimize\n\n\n\noptimize.left_edge\n\n\n\n\n\n\n\n\n\n\nwrite_data\nSave data.\n\n\npickle_speakers\nThis will serialize a SpeakerCollection to a pickle\n\n\nunpickle_speakers\nUnpickle a pickled SpeakerCollection\n\n\n\n\n\n\n\n\n\nutils.local_resources.local_resources\n\n\n\n\n\n\n\n\n\n\nspeaker.speaker.Speaker\nThis is a class to represent speaker information.",
    "crumbs": [
      "Function reference"
    ]
  },
  {
    "objectID": "reference/index.html#processing-patterns",
    "href": "reference/index.html#processing-patterns",
    "title": "Function reference",
    "section": "",
    "text": "Different patterns for processing data\n\n\n\nfave_audio_textgrid\nProcess a single audio/textgrid pair.\n\n\nfave_corpus\nProcess a corpus directory.\n\n\nfave_subcorpora\nProcess multiple subcorpora",
    "crumbs": [
      "Function reference"
    ]
  },
  {
    "objectID": "reference/index.html#vowel-measurements",
    "href": "reference/index.html#vowel-measurements",
    "title": "Function reference",
    "section": "",
    "text": "measurements.vowel_measurement\nThis module contains classes to represent vowel measurements and their\n\n\nVowelMeasurement\nA class used to represent a vowel measurement.\n\n\nVowelClass\nA class used to represent a vowel class.\n\n\nVowelClassCollection\nA class for an entire vowel system.\n\n\nSpeakerCollection\nA class to represent the vowel system of all",
    "crumbs": [
      "Function reference"
    ]
  },
  {
    "objectID": "reference/index.html#calculations",
    "href": "reference/index.html#calculations",
    "title": "Function reference",
    "section": "",
    "text": "measurements.calcs.mahalanobis\nCalculates the Mahalanobis distance.",
    "crumbs": [
      "Function reference"
    ]
  },
  {
    "objectID": "reference/index.html#optimization",
    "href": "reference/index.html#optimization",
    "title": "Function reference",
    "section": "",
    "text": "Functions for optimizing formant measurements\n\n\n\noptimize.optimize\n\n\n\noptimize.left_edge",
    "crumbs": [
      "Function reference"
    ]
  },
  {
    "objectID": "reference/index.html#writers",
    "href": "reference/index.html#writers",
    "title": "Function reference",
    "section": "",
    "text": "write_data\nSave data.\n\n\npickle_speakers\nThis will serialize a SpeakerCollection to a pickle\n\n\nunpickle_speakers\nUnpickle a pickled SpeakerCollection",
    "crumbs": [
      "Function reference"
    ]
  },
  {
    "objectID": "reference/index.html#built-in-resources",
    "href": "reference/index.html#built-in-resources",
    "title": "Function reference",
    "section": "",
    "text": "utils.local_resources.local_resources",
    "crumbs": [
      "Function reference"
    ]
  },
  {
    "objectID": "reference/index.html#speaker-files",
    "href": "reference/index.html#speaker-files",
    "title": "Function reference",
    "section": "",
    "text": "speaker.speaker.Speaker\nThis is a class to represent speaker information.",
    "crumbs": [
      "Function reference"
    ]
  },
  {
    "objectID": "reference/SpeakerCollection.html",
    "href": "reference/SpeakerCollection.html",
    "title": "SpeakerCollection",
    "section": "",
    "text": "SpeakerCollection(self, track_list=[])\nA class to represent the vowel system of all speakers in a TextGrid.\n\n\nIt is a subclass of defaultdict, and can be keyed by the (file_name, group_name) tuple.\nvowel_measurements = [VowelMeasurement(t) for t in fasttrack_tracks]\nspeakers = SpeakerCollection(vowel_measurements)\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ntrack_list\nlist[VowelMeasurement]\nA list of VowelMeasurements.\n[]\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nto_param_df\nThis will return a dataframe of the DCT parameters for all speakers.\n\n\nto_point_df\nThis will return a DataFrame of point measurements\n\n\nto_tracks_df\nThis will return a data frame of formant\n\n\n\n\n\nSpeakerCollection.to_param_df(output='log_param')\nThis will return a dataframe of the DCT parameters for all speakers. If output is passed param, it will be the DCT parameters in the original Hz. If passed log_param, it will be the DCT parameters over log(Hz).\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\noutput\nLiteral[‘param’, ‘log_param’]\nWhich set of DCT parameters to return. Defaults to “log_param”.\n'log_param'\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npl.DataFrame\nA DataFrame of DCT parameters for all speakers.\n\n\n\n\n\n\n\nSpeakerCollection.to_point_df()\nThis will return a DataFrame of point measurements for all speakers Returns: (pl.DataFrame): A DataFrame of vowel point measurements.\n\n\n\nSpeakerCollection.to_tracks_df()\nThis will return a data frame of formant tracks for all speakers.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npl.DataFrame\nA dataframe of formant tracks for all speakers.",
    "crumbs": [
      "Vowel Measurements",
      "SpeakerCollection"
    ]
  },
  {
    "objectID": "reference/SpeakerCollection.html#intended-usage",
    "href": "reference/SpeakerCollection.html#intended-usage",
    "title": "SpeakerCollection",
    "section": "",
    "text": "It is a subclass of defaultdict, and can be keyed by the (file_name, group_name) tuple.\nvowel_measurements = [VowelMeasurement(t) for t in fasttrack_tracks]\nspeakers = SpeakerCollection(vowel_measurements)",
    "crumbs": [
      "Vowel Measurements",
      "SpeakerCollection"
    ]
  },
  {
    "objectID": "reference/SpeakerCollection.html#parameters",
    "href": "reference/SpeakerCollection.html#parameters",
    "title": "SpeakerCollection",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\ntrack_list\nlist[VowelMeasurement]\nA list of VowelMeasurements.\n[]",
    "crumbs": [
      "Vowel Measurements",
      "SpeakerCollection"
    ]
  },
  {
    "objectID": "reference/SpeakerCollection.html#methods",
    "href": "reference/SpeakerCollection.html#methods",
    "title": "SpeakerCollection",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nto_param_df\nThis will return a dataframe of the DCT parameters for all speakers.\n\n\nto_point_df\nThis will return a DataFrame of point measurements\n\n\nto_tracks_df\nThis will return a data frame of formant\n\n\n\n\n\nSpeakerCollection.to_param_df(output='log_param')\nThis will return a dataframe of the DCT parameters for all speakers. If output is passed param, it will be the DCT parameters in the original Hz. If passed log_param, it will be the DCT parameters over log(Hz).\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\noutput\nLiteral[‘param’, ‘log_param’]\nWhich set of DCT parameters to return. Defaults to “log_param”.\n'log_param'\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npl.DataFrame\nA DataFrame of DCT parameters for all speakers.\n\n\n\n\n\n\n\nSpeakerCollection.to_point_df()\nThis will return a DataFrame of point measurements for all speakers Returns: (pl.DataFrame): A DataFrame of vowel point measurements.\n\n\n\nSpeakerCollection.to_tracks_df()\nThis will return a data frame of formant tracks for all speakers.\n\n\n\n\n\n\n\n\n\nType\nDescription\n\n\n\n\npl.DataFrame\nA dataframe of formant tracks for all speakers.",
    "crumbs": [
      "Vowel Measurements",
      "SpeakerCollection"
    ]
  },
  {
    "objectID": "reference/utils.local_resources.local_resources.html",
    "href": "reference/utils.local_resources.local_resources.html",
    "title": "utils.local_resources.local_resources",
    "section": "",
    "text": "utils.local_resources.local_resources()\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\nrecodes\ndict\nRecode options. Contains \"cmu2phila\" and \"cmu2labov\"\n\n\nparsers\ndict\nLabelset parsers. Contains \"cmu_parser\"\n\n\nheursitics\ndict\nMeasurement point heuristics. Contains \"fave\"\n\n\nvowel_place\ndict\nVowel place definitions\n\n\nfasttrack_config\ndict\nFastTrack config. Contains \"default\"",
    "crumbs": [
      "Built-in resources",
      "utils.local_resources.local_resources"
    ]
  },
  {
    "objectID": "reference/utils.local_resources.local_resources.html#attributes",
    "href": "reference/utils.local_resources.local_resources.html#attributes",
    "title": "utils.local_resources.local_resources",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\nrecodes\ndict\nRecode options. Contains \"cmu2phila\" and \"cmu2labov\"\n\n\nparsers\ndict\nLabelset parsers. Contains \"cmu_parser\"\n\n\nheursitics\ndict\nMeasurement point heuristics. Contains \"fave\"\n\n\nvowel_place\ndict\nVowel place definitions\n\n\nfasttrack_config\ndict\nFastTrack config. Contains \"default\"",
    "crumbs": [
      "Built-in resources",
      "utils.local_resources.local_resources"
    ]
  },
  {
    "objectID": "dev/index.html",
    "href": "dev/index.html",
    "title": "Development Plan",
    "section": "",
    "text": "The plan is for new-fave to be more opinionated about the input data stucture. fasttrackpy is more general purpose and therefore has its own design approach.\n\n\n\nThe plan is for new-fave to bring together, under one tool\n\nfave-recodeing of input data, allowing for dialect, language, or research question specific recoding of alignment output\nCustomizable point measurement heuristics\nEnriched data output enabled by its opinionated approach to data input. (e.g. fave-syllabify)\n\n\n\n\nSee New-Fave Approach"
  },
  {
    "objectID": "dev/index.html#what-is-favey-about-this",
    "href": "dev/index.html#what-is-favey-about-this",
    "title": "Development Plan",
    "section": "",
    "text": "The plan is for new-fave to be more opinionated about the input data stucture. fasttrackpy is more general purpose and therefore has its own design approach.\n\n\n\nThe plan is for new-fave to bring together, under one tool\n\nfave-recodeing of input data, allowing for dialect, language, or research question specific recoding of alignment output\nCustomizable point measurement heuristics\nEnriched data output enabled by its opinionated approach to data input. (e.g. fave-syllabify)\n\n\n\n\nSee New-Fave Approach"
  },
  {
    "objectID": "index.html#where-to-go",
    "href": "index.html#where-to-go",
    "title": "new-fave",
    "section": "Where to go:",
    "text": "Where to go:\nGetting Started How it Works Customization Configuration",
    "crumbs": [
      "Home",
      "new-fave"
    ]
  },
  {
    "objectID": "index.html#what-is-new-fave",
    "href": "index.html#what-is-new-fave",
    "title": "new-fave",
    "section": "What is new-fave?",
    "text": "What is new-fave?\nnew-fave is a tool for automating and optimizing vowel formant extraction. It is philosophically similar (and named after) the FAVE-suite. However, new-fave has been completely written from scratch, and has some key differences from the FAVE-suite.\n\nnew-fave does not include a forced-aligner. It can process alignments produced by fave-align, but we would recommend using the Monteal Forced Aligner instead\nnew-fave does not require speaker demographics. You can optionally pass fave-extract a speaker demographics file to be merged into your formant data, but this does not influence how the data is processed in any way. Besides including file name and speaker number data, you can pass any demographic information you would like.\nnew-fave does not assume North American English vowels. Your alignments can contain any set of vowels, in any transcription system, as long as you can provide a regular expression to identify them.\nnew-fave is customizable. With config files, you can customize vowel recoding, labelset parsing, and point measurement heuristics.\nnew-fave is focused on formant tracks. You can still produce single point measurements for vowels, but new-fave is built upon the FastTrack method. By default, it will write output files including point measurements, full formant tracks, and Discrete Cosine Transform coefficients.\nnew-fave is maintainable. As time goes on, and the code base needs updating, the organization and infrastructure of new-fave should allow it to be readilly updateable.\n\nYou can read more on the getting started page.",
    "crumbs": [
      "Home",
      "new-fave"
    ]
  },
  {
    "objectID": "index.html#installation",
    "href": "index.html#installation",
    "title": "new-fave",
    "section": "Installation",
    "text": "Installation\nYou can install new-fave with pip.\n# bash\npip install new-fave",
    "crumbs": [
      "Home",
      "new-fave"
    ]
  },
  {
    "objectID": "index.html#usage",
    "href": "index.html#usage",
    "title": "new-fave",
    "section": "Usage",
    "text": "Usage\nTo use the default settings (which assume CMU dictionary transcriptions), you can use one of these patterns.\n\nA single audio + textgrid pair\n# bash\nfave-extract audio-textgrid speaker1.wav speaker1.TextGrid\n\n\nA directory of audio + textgrid pairs\n# bash\nfave-extract corpus speakers/\n\n\nMultiple subdirectories of audio + textgrid pairs\n# bash\nfave-extract subcorpora data/*",
    "crumbs": [
      "Home",
      "new-fave"
    ]
  },
  {
    "objectID": "usage/getting_started.html",
    "href": "usage/getting_started.html",
    "title": "Getting Started",
    "section": "",
    "text": "We expect new-fave to be primarily used as a command-line tool. This page outlines that usage. Using new-fave this way does not require you to do any python programming, but if you would like to import new-fave into a python project of your own, see the page on Python Usage.",
    "crumbs": [
      "Home",
      "Usage",
      "Getting Started"
    ]
  },
  {
    "objectID": "usage/getting_started.html#audio-textgrid",
    "href": "usage/getting_started.html#audio-textgrid",
    "title": "Getting Started",
    "section": "audio-textgrid",
    "text": "audio-textgrid\nIn the simplest case of a single audio/textgrid pair, your best option is the audio-textgrid subcommand. For example, if you had the following files in a data/ directory:\n\n\ndata\n├── speaker1.TextGrid\n└── speaker1.wav\n\n\nTo use all default settings, you would run the following:\n# command-line\nfave-extract audio-textgrid data/speaker1.wav data/speaker1.TextGrid\nTo customize the way fave-extract audio-textgrid works, including how to incorporate speaker demographics into the output, see the customization documentation.",
    "crumbs": [
      "Home",
      "Usage",
      "Getting Started"
    ]
  },
  {
    "objectID": "usage/getting_started.html#corpus",
    "href": "usage/getting_started.html#corpus",
    "title": "Getting Started",
    "section": "corpus",
    "text": "corpus\nIf you have all of your audio file/textgrid pairs in a single directory, then the corpus subcommand is your best option. An example file organization would look like this:\n\n\nmy_corpus\n├── recordingA.TextGrid\n├── recordingA.wav\n├── recordingB.TextGrid\n└── recordingB.wav\n\n\n\n\n\n\n\n\nFile Naming\n\n\n\nThe corpus subcommand will only work if the file names are the the same for the audio/textgrid pairs. That is, if your audio files are named something like speaker1.wav, and your textgrids are named something like speaker1_aligned.TextGrid, the corpus subcommand won’t process them.\n\n\nTo use all default settings, you would run the following:\n# command-line\nfave-extract corpus my_corpus/\nTo customize the way fave-extract corpus works, including how to incorporate speaker demographics into the output, see the customization documentation.",
    "crumbs": [
      "Home",
      "Usage",
      "Getting Started"
    ]
  },
  {
    "objectID": "usage/getting_started.html#subcorpora",
    "href": "usage/getting_started.html#subcorpora",
    "title": "Getting Started",
    "section": "subcorpora",
    "text": "subcorpora\nIf each audio file/textgrid pair is in its own directory inside of a larger project directory, then the subcorpora subcommand is the best to use. An example file organization would look like this:\n\n\nbig_project\n├── speaker1\n│   ├── notes.txt\n│   ├── speaker1.TextGrid\n│   └── speaker1.wav\n└── speaker2\n    ├── notes.txt\n    ├── speaker2.TextGrid\n    └── speaker2.wav\n\n\n\n\n\n\n\n\nFile Naming\n\n\n\nThe corpus subcommand will only work if the file names are the the same for the audio/textgrid pairs. That is, if your audio files are named something like speaker1.wav, and your textgrids are named something like speaker1_aligned.TextGrid, the corpus subcommand won’t process them.\n\n\nTo use all default settings, you would run the following:\n# command-line\nfave-extract subcorpora big_project/speaker*\nTo customize the way fave-extract subcorpora works, including how to incorporate speaker demographics into the output, see the customization documentation.",
    "crumbs": [
      "Home",
      "Usage",
      "Getting Started"
    ]
  },
  {
    "objectID": "usage/configs/recode-rules.html",
    "href": "usage/configs/recode-rules.html",
    "title": "Recode Rules and Labelset Parser",
    "section": "",
    "text": "See fave-recode for the full details on how to write label recoding rules.\nA recoding rules file is a yaml file with a list of rules, which are applied in order. When writing a rule set, you must implement the Elsewhere Principle, and place more specific rules at the top of the rule file.",
    "crumbs": [
      "Home",
      "Usage",
      "Configuration",
      "Recode Rules and Labelset Parser"
    ]
  },
  {
    "objectID": "usage/configs/recode-rules.html#a-rule-example",
    "href": "usage/configs/recode-rules.html#a-rule-example",
    "title": "Recode Rules and Labelset Parser",
    "section": "A rule Example",
    "text": "A rule Example\nAn example of a single-rule file to recode CMU AH0 to @ (schwa) would look like this:\n# yaml\n- rule: schwa\n  conditions:\n    - attribute: label\n      relation: ==\n      set: AH0\n  return: \"@\"\nEach rule has\n\nA name\nA list of conditions that define when it applies\n\nEach condition targets an interval’s attribute\nA relation to some other value\nThe other value\n\nA return label",
    "crumbs": [
      "Home",
      "Usage",
      "Configuration",
      "Recode Rules and Labelset Parser"
    ]
  },
  {
    "objectID": "usage/configs/recode-rules.html#a-collection-of-rules",
    "href": "usage/configs/recode-rules.html#a-collection-of-rules",
    "title": "Recode Rules and Labelset Parser",
    "section": "A collection of rules",
    "text": "A collection of rules\nLet’s say you wanted to recode CMU AY into three different categories\n\nayE: /ay/ that appears in words with exceptional raising, like “spider” and “cider”\nay0: /ay/ that appears before voiceless consonants\nay: /ay/ that appears in all other contexts\n\nThe recode rule file would look like:\n# yaml\n## placing most specific rule\n## at top\n- rule: exceptional\n  returns: ayE\n  conditions:\n    - attribute: label\n      relation: contains\n      set: AY\n    - attribute: inword.label\n      relation: in\n      set:\n        - SPIDER\n        - CIDER        \n\n## Next most specific rule\n- rule: ay0\n  returns: ay0\n  conditions:\n    - attribute: label\n      relation: contains\n      set: AY\n    - attribute: fol.label\n      attribute: in\n      set: [CH, F, HH, K, P, S, SH, T, TH]\n\n## Elsewhere rule\n- rule: ay\n  returns: ay\n  conditions:\n    - attribute: label\n      relation: contains\n      set: AY",
    "crumbs": [
      "Home",
      "Usage",
      "Configuration",
      "Recode Rules and Labelset Parser"
    ]
  },
  {
    "objectID": "usage/configs/recode-rules.html#more-details",
    "href": "usage/configs/recode-rules.html#more-details",
    "title": "Recode Rules and Labelset Parser",
    "section": "More details",
    "text": "More details\nFor more details on the kinds of attributes that are definable in a rules file\n\nCondition Attributes\n\nFor more details on the kinds of relations that are definable in a rules file\n\nCondition Relations\n\nFor more details on how return labels can be defined, see\n\nLabel Set Parsers",
    "crumbs": [
      "Home",
      "Usage",
      "Configuration",
      "Recode Rules and Labelset Parser"
    ]
  },
  {
    "objectID": "usage/configs/point-heuristic.html",
    "href": "usage/configs/point-heuristic.html",
    "title": "Measurement Point Customization",
    "section": "",
    "text": "For more on measurement point definitions, see the fave measurement point package documentation.",
    "crumbs": [
      "Home",
      "Usage",
      "Configuration",
      "Measurement Point Customization"
    ]
  },
  {
    "objectID": "usage/configs/point-heuristic.html#specifics",
    "href": "usage/configs/point-heuristic.html#specifics",
    "title": "Measurement Point Customization",
    "section": "Specifics",
    "text": "Specifics\nLet’s say you wanted to define a special measurement point rule for just the vowel /ay/, to measure it at maximum F1. This can be done by adding the following rule to the specifics list.\nheuristic: ay-rule\ndefault:\n    prop_time: \"1/3\"\nspecifics:\n    - label: ay\n      prop_time: f1.max.prop_time\nWhat this says is:\n\nApply a special measurement point rule when the interval label is “ay”.\nGet the measurement point where the vowel’s prop_time is equal to the prop_time of F1 maximum.",
    "crumbs": [
      "Home",
      "Usage",
      "Configuration",
      "Measurement Point Customization"
    ]
  },
  {
    "objectID": "usage/configs/point-heuristic.html#valid-point-expressions",
    "href": "usage/configs/point-heuristic.html#valid-point-expressions",
    "title": "Measurement Point Customization",
    "section": "Valid point expressions",
    "text": "Valid point expressions\nThe expression f1.max.prop_time defines the proportional time of F1 maximum. An entire point expression will always be of the format:\nformant.anchor.time\nValid values for each slot are:\n\nFormants\n\nf1, f2, f3, …\nAny formant that’s available\n\nAnchor\n\nmin\nmax\n\nTime\n\ntime\nrel_time\nprop_time\n\n\nAdditionally, any other mathematical expression can be included. For example, the original FAVE suite had a measurement point heuristic for /aw/ and /ow/ defined in the docs as:\n# - OW, AW measured halfway between beginning of segment and F1 maximum  ##\nThe heuristic file for this would look like:\n# yaml\nheuristic: aw-ow-rule\ndefault:\n    prop_time: \"1/3\"\nspecifics:\n    - label: aw\n      prop_time: f1.max.prop_time / 2\n    - label: ow\n      prop_time: f1.max.prop_time / 2",
    "crumbs": [
      "Home",
      "Usage",
      "Configuration",
      "Measurement Point Customization"
    ]
  },
  {
    "objectID": "usage/configs/ft-config.html",
    "href": "usage/configs/ft-config.html",
    "title": "FastTrack Config",
    "section": "",
    "text": "For more details on how to configure FastTrack, see the fasttrackpy documentation. Any fasttrackpy config file can be passed to a fave-extract subcommand.\nFor example, if you wanted to adjust the range of max-formants considered by fasttrack, you could create a config file like so:\n# fasttrack.yml\nmin_max_formant: 3000\nmax_max_formant: 6000\nThen you would pass this the –ft-config option.\n# command-line\nfave-extract corpus my_corpus \\\n    --ft-config fasttrack.yml",
    "crumbs": [
      "Home",
      "Usage",
      "Configuration",
      "FastTrack Config"
    ]
  },
  {
    "objectID": "usage/customizing/demographics.html",
    "href": "usage/customizing/demographics.html",
    "title": "Adding Speaker Demographics",
    "section": "",
    "text": "We’ve tried to make adding speaker demographics to fave-extract output as flexible as possible, including",
    "crumbs": [
      "Home",
      "Usage",
      "Customizing",
      "Adding Speaker Demographics"
    ]
  },
  {
    "objectID": "usage/customizing/demographics.html#excel-csv",
    "href": "usage/customizing/demographics.html#excel-csv",
    "title": "Adding Speaker Demographics",
    "section": "Excel or CSV files",
    "text": "Excel or CSV files\nTo ensure demographic information in a an .xlsx or .csv file is correctly included in fave-extract output two columns are required:\n\n\n\n\n\n\nRequired Columns\n\n\n\n\nfile_name: The file stem of the wav and textgrid files\nspeaker_num: The speaker to be analyzed in a file. the first speaker is 1.\n\n\n\nSo, if you had a corpus that looked like this:\n\n\n../my_corpus\n├── recordingA.TextGrid\n├── recordingA.wav\n├── recordingB.TextGrid\n└── recordingB.wav\n\n\nYour excel file or csv file would have to look something like this:\n\n\n\n\n\n\n\n\nfile_name\nspeaker_num\nage\n\n\n\n\nrecordingA\n1\n26\n\n\nrecordingB\n1\n50\n\n\nrecordingB\n2\n23\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nIf a speaker demographics file is provided, fave-extract will only process data for speakers with entries.",
    "crumbs": [
      "Home",
      "Usage",
      "Customizing",
      "Adding Speaker Demographics"
    ]
  },
  {
    "objectID": "usage/customizing/demographics.html#yaml-file",
    "href": "usage/customizing/demographics.html#yaml-file",
    "title": "Adding Speaker Demographics",
    "section": "YAML file",
    "text": "YAML file\nAnother option for formatting speaker demographic information is in a yaml file. Yaml is a very flexible data structuring format. For this corpus:\n\n\n../my_corpus\n├── recordingA.TextGrid\n├── recordingA.wav\n├── recordingB.TextGrid\n└── recordingB.wav\n\n\nA speaker demographics yaml file would look like\n# yaml\n- file_name: recordingA\n  speaker_num: 1\n  age: 26\n- file_name: recordingB\n  speaker_num: 1\n  age: 50\n- file_name: recordingB\n  speaker_num: 1\n  age: 23  \n\n\n\n\n\n\nRequired Fields\n\n\n\nThe file_name and speaker_num fields are required.\n\n\n\n\n\n\n\n\nFlexibility\n\n\n\nOutside of the required fields\n\nNot every speaker has to have the same fields defined.\nThe fields don’t need to appear in a consistent order.",
    "crumbs": [
      "Home",
      "Usage",
      "Customizing",
      "Adding Speaker Demographics"
    ]
  },
  {
    "objectID": "usage/customizing/demographics.html#legacy-fave-speaker-file",
    "href": "usage/customizing/demographics.html#legacy-fave-speaker-file",
    "title": "Adding Speaker Demographics",
    "section": "Legacy-fave speaker file",
    "text": "Legacy-fave speaker file\nIf you have legacy-fave .speaker files, you can pass them to the --speakers option.",
    "crumbs": [
      "Home",
      "Usage",
      "Customizing",
      "Adding Speaker Demographics"
    ]
  },
  {
    "objectID": "usage/customizing/processing.html",
    "href": "usage/customizing/processing.html",
    "title": "Processing Options",
    "section": "",
    "text": "Some important additional options you can set for a fave-extract subcommand are:\n\n--fave-aligned: Was the TextGrid aligned using legacy-fave align?\n--exclude-overlaps: Should overlapping speech be excluded?\n--no-optimize: Should the optimization steps be skipped?\n--f1-cutoff: The maximum considerable F1 value\n--f2-cutoff: The maximum considerable F2 value",
    "crumbs": [
      "Home",
      "Usage",
      "Customizing",
      "Processing Options"
    ]
  },
  {
    "objectID": "usage/customizing/index.html",
    "href": "usage/customizing/index.html",
    "title": "Customizing",
    "section": "",
    "text": "Adding Speaker Demographics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOutput Options\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProcessing Options\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReference Values\n\n\n\n\n\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Home",
      "Usage",
      "Customizing"
    ]
  },
  {
    "objectID": "usage/subcommands/audio-textgrid.html",
    "href": "usage/subcommands/audio-textgrid.html",
    "title": "audio-textgrid",
    "section": "",
    "text": "fave-extract audio-textgrid --help\n\nUsage: fave-extract audio-textgrid [OPTIONS] AUDIO_PATH\n                                   TEXTGRID_PATH\nAliases: audio-textgrid\n\n  Run fave-extract on a single audio+textgrid pair.\n\nPositional arguments:\n  AUDIO_PATH                      Path to the audio file.\n  TEXTGRID_PATH                   Path to the TextGrid file.\n\nConfiguration Options:\n  --recode-rules TEXT             Recoding rules to adjust vowel interval\n                                  labels. Values can be a string naming one of\n                                  the built-in recode rules\n                                  ('cmu2labov','cmu2phila', 'norecode'), or a\n                                  path to a custom recoding yml file.\n                                  [default: cmu2labov]\n  --add-rules TEXT                Additional recoding rules to be added to the\n                                  provided ruleset. New rules will be run\n                                  first.\n  --labelset-parser TEXT          A labeleset parser. Values can be a string\n                                  naming a built-in parser ('cmu_parser') or a\n                                  path to a custom parser yml file.   [default:\n                                  cmu_parser]\n  --point-heuristic TEXT          The point measurement heuristic to use.\n                                  Values can be a built in heuristic ('fave')\n                                  or a path to a custom heuristic file.\n                                  [default: fave]\n  --vowel-place TEXT              A vowel place definition file. Values can be\n                                  the name of a built in config ('defailt) or a\n                                  path to a custom config file.  [default:\n                                  default]\n  --f1-cutoff FLOAT               The maximum considerable F1 value.  [default:\n                                  1500]\n  --f2-cutoff FLOAT               The maximum considerable F2 value.  [default:\n                                  3500]\n  --ft-config TEXT                A fasttrack config file. Values can be the\n                                  name of a built in config ('default') or a\n                                  path to a custom config file.  [default:\n                                  default]\n  --fave-aligned                  Include this flag if the textgrid was aligned\n                                  with FAVE align.\n  --exclude-overlaps              Include this flag if you want to exclude\n                                  overlapping speech.\n  --no-optimize                   Include this flag if you want to skip fave\n                                  optimization\n\nReference Values: [mutually exclusive]\n  --logparam-reference DIRECTORY  A path to a collection of reference\n                                  *_logparam.csv files.\n  --param-reference DIRECTORY     A path to a collection of reference\n                                  *_param.csv files.\n  --points-reference DIRECTORY    A path to a collection of reference\n                                  *_points.csv files.\n\nOutput options:\n  Options for writing output data.\n  --destination DIRECTORY         Destination directory for resulting data\n                                  files. If the directory doesn't exist, it\n                                  will be created.  [default: fave_results]\n  --which [all|tracks|points|param|log_param|textgrid]\n                                  Which output files to write. Default is\n                                  'all'. This option can be included multiple\n                                  times to write just some of the options (e.g.\n                                  'tracks' and 'points'  [default: all]\n  --separate                      Should each individual speaker be written to\n                                  separate data files?\n\nOther options:\n  --speakers TEXT                 Which speakers to analyze. Values can be: a\n                                  numeric value (1 = first speaker), the string\n                                  'all', for all speakers, or a path to a\n                                  speaker demographics file.  [default: 1]\n  --help                          Show this message and exit."
  }
]